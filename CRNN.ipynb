{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import random\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, ColorJitter, Compose, Normalize\n",
    "\n",
    "from torch import nn\n",
    "from torch.nn import Module\n",
    "from torch.nn import Conv2d\n",
    "from torch.nn import Linear\n",
    "from torch.nn import ReLU\n",
    "from torch.nn import LogSoftmax\n",
    "from torch.nn import BatchNorm2d\n",
    "from torch.nn import LSTM\n",
    "from torch import flatten\n",
    "from torchmetrics import CharErrorRate\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import CTCLoss\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alphabet class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Alphabet(object):\n",
    "    def __init__(self, folder_path):\n",
    "        self.symbol2idx = {}\n",
    "        self.idx2symbol = []\n",
    "        self._len = 0\n",
    "        self.make_alphabet(folder_path)\n",
    "        \n",
    "    def add_symbol(self, s):\n",
    "        if s not in self.symbol2idx:\n",
    "            self.idx2symbol.append(s)\n",
    "            self.symbol2idx[s] = self._len\n",
    "            self._len += 1\n",
    "            \n",
    "    def make_alphabet(self, folder_path):\n",
    "        assert os.path.exists(folder_path)\n",
    "        for _, _, files in os.walk(folder_path):\n",
    "            for file_name in files:\n",
    "                file_name = file_name.split('.')[0]\n",
    "                for symbol in file_name:\n",
    "                    self.add_symbol(symbol)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self._len\n",
    "    \n",
    "    def encode(self, label):\n",
    "        ids = torch.zeros([len(label), len(self)], dtype=torch.float32)\n",
    "        for pos, symbol in enumerate(label):\n",
    "            ids[pos, self.symbol2idx[symbol]] = 1.\n",
    "        return ids\n",
    "    \n",
    "    def decode(self, ids):\n",
    "        idxs = ids.argmax(dim=2).tolist()\n",
    "        labels = [''.join([self.idx2symbol[i] for i in b]) for b in idxs]\n",
    "        return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dir = './samples/'\n",
    "\n",
    "alphabet = Alphabet(img_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, img_dir, transform=None):\n",
    "        self.img_labels = []\n",
    "        for _, _, files in os.walk(img_dir):\n",
    "            for file_ in files:\n",
    "                self.img_labels.append(file_)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        filename = self.img_labels[idx]\n",
    "        img_path = os.path.join(self.img_dir, filename)\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        label = alphabet.encode(filename.split('.')[0])\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_files = []\n",
    "for _, _, files in os.walk(img_dir):\n",
    "    for file_ in files:\n",
    "        all_files.append(file_)\n",
    "        \n",
    "random.shuffle(all_files)\n",
    "border = int(0.8 * len(all_files))\n",
    "train_files = all_files[:border]\n",
    "test_files = all_files[border:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_dir = 'data/train/'\n",
    "test_data_dir = 'data/test/'\n",
    "\n",
    "if not os.path.exists(train_data_dir):\n",
    "    os.makedirs(train_data_dir)\n",
    "    for file in train_files:\n",
    "        shutil.copy(os.path.join(img_dir, file), train_data_dir)\n",
    "\n",
    "if not os.path.exists(test_data_dir):\n",
    "    os.makedirs(test_data_dir)\n",
    "    for file in test_files:\n",
    "        shutil.copy(os.path.join(img_dir, file), test_data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find mean and std of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CustomImageDataset(img_dir=train_data_dir,\n",
    "                                   transform=Compose([\n",
    "                                            ColorJitter(),\n",
    "                                            ToTensor(),\n",
    "                                   ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = DataLoader(dataset, batch_size=16, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.7151, 0.7151, 0.7151])\n",
      "tensor([0.3135, 0.3135, 0.3135])\n"
     ]
    }
   ],
   "source": [
    "nimages = 0\n",
    "mean = 0.0\n",
    "var = 0.0\n",
    "for i_batch, batch_target in enumerate(data_loader):\n",
    "    batch = batch_target[0]\n",
    "    # Rearrange batch to be the shape of [B, C, W * H]\n",
    "    batch = batch.view(batch.size(0), batch.size(1), -1)\n",
    "    # Update total number of images\n",
    "    nimages += batch.size(0)\n",
    "    # Compute mean and std here\n",
    "    mean += batch.mean(2).sum(0) \n",
    "    var += batch.var(2).sum(0)\n",
    "\n",
    "mean /= nimages\n",
    "var /= nimages\n",
    "std = torch.sqrt(var)\n",
    "\n",
    "print(mean)\n",
    "print(std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomImageDataset(img_dir=train_data_dir,\n",
    "                                   transform=Compose([\n",
    "                                            #ColorJitter(),\n",
    "                                            ToTensor(),\n",
    "                                            Normalize(mean=[0.7151, 0.7151, 0.7151], std=[0.3136, 0.3136, 0.3136]),\n",
    "                                   ]))\n",
    "\n",
    "test_dataset = CustomImageDataset(img_dir=test_data_dir,\n",
    "                                  transform=Compose([\n",
    "                                            ToTensor(),\n",
    "                                            Normalize(mean=[0.7151, 0.7151, 0.7151], std=[0.3136, 0.3136, 0.3136]),\n",
    "                                 ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=10, shuffle=True, num_workers=6)\n",
    "test_loader = DataLoader(test_dataset, batch_size=10, shuffle=False, num_workers=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bidirectional_LSTM(torch.nn.Module):\n",
    "    def __init__(self, class_num, hidden_unit):\n",
    "        super(Bidirectional_LSTM, self).__init__()\n",
    "        \n",
    "        self.LSTM1 = torch.nn.LSTM(2048, hidden_unit, bidirectional=True, dropout=0.2)\n",
    "        self.embedding1 = torch.nn.Linear(hidden_unit * 2, 2048)\n",
    "        self.LSTM2 = torch.nn.LSTM(2048, hidden_unit, bidirectional=True, dropout=0.2)\n",
    "        self.embedding2 = torch.nn.Linear(hidden_unit * 2, class_num)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.LSTM1(x)   # LSTM output: output, (h_n, c_n)\n",
    "        T, b, h = x[0].size()   # x[0]: (seq_len, batch, num_directions * hidden_size)\n",
    "        x = self.embedding1(x[0].view(T * b, h))  # pytorch view() reshape as [T * b, nOut]\n",
    "        x = x.view(T, b, -1)  # [seq_len, b, 512]\n",
    "        \n",
    "        x = self.LSTM2(x)\n",
    "        T, b, h = x[0].size()\n",
    "        x = self.embedding2(x[0].view(T * b, h))\n",
    "        x = x.view(T, b, -1)\n",
    "        \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CapchaNet(Module):\n",
    "    def __init__(self, alphabet_len):\n",
    "        super(CapchaNet, self).__init__()\n",
    "        \n",
    "        self.conv1 = Conv2d(3, 128, (3, 3), stride=2) # 99x24\n",
    "        self.bn1 = BatchNorm2d(128)\n",
    "        self.conv2 = Conv2d(128, 256, (3, 3), stride=2) # 48x11\n",
    "        self.bn2 = BatchNorm2d(256)\n",
    "        self.conv3 = Conv2d(256, 512, (3, 3), stride=2) # 23x5\n",
    "        self.bn3 = BatchNorm2d(512)\n",
    "        self.conv4 = Conv2d(512, 1024, (3, 3), stride=2) # 11x2\n",
    "        self.bn4 = BatchNorm2d(1024)\n",
    "        self.conv5 = Conv2d(1024, 2048, (2, 2), stride=(1, 2)) # 5X1\n",
    "        self.bn5 = BatchNorm2d(2048)\n",
    "        #self.conv6 = Conv2d(2048, 4096, (1, 1)) # 5X1\n",
    "        #self.bn6 = BatchNorm2d(4096)\n",
    "        self.rnn = Bidirectional_LSTM(alphabet_len, 2048)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.bn1(F.relu(self.conv1(x)))\n",
    "        x = self.bn2(F.relu(self.conv2(x)))\n",
    "        x = self.bn3(F.relu(self.conv3(x)))\n",
    "        x = self.bn4(F.relu(self.conv4(x)))\n",
    "        x = self.bn5(F.relu(self.conv5(x)))\n",
    "        #x = self.bn6(F.relu(self.conv6(x)))\n",
    "        \n",
    "        x = x.squeeze(2)  # remove h dimension\n",
    "        x = x.permute(2, 0, 1)  # [w, b, c] = [seq_len, batch, input_size]\n",
    "        x = self.rnn(x)\n",
    "        \n",
    "        x = x.permute(1, 0, 2)\n",
    "        output = F.log_softmax(x, dim=2)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alex/anaconda3/lib/python3.8/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "import math\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "ntokens = len(alphabet)\n",
    "model = CapchaNet(ntokens)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "grad_clip = 0.1\n",
    "lr = torch.tensor(2e-4)\n",
    "optim = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "scheduler = lr_scheduler.ReduceLROnPlateau(optim, mode='min',\n",
    "                                           factor=0.5, patience=7, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CapchaNet(\n",
       "  (conv1): Conv2d(3, 128, kernel_size=(3, 3), stride=(2, 2))\n",
       "  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv2): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2))\n",
       "  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv3): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2))\n",
       "  (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv4): Conv2d(512, 1024, kernel_size=(3, 3), stride=(2, 2))\n",
       "  (bn4): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv5): Conv2d(1024, 2048, kernel_size=(2, 2), stride=(1, 2))\n",
       "  (bn5): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (rnn): Bidirectional_LSTM(\n",
       "    (LSTM1): LSTM(2048, 2048, dropout=0.2, bidirectional=True)\n",
       "    (embedding1): Linear(in_features=4096, out_features=2048, bias=True)\n",
       "    (LSTM2): LSTM(2048, 2048, dropout=0.2, bidirectional=True)\n",
       "    (embedding2): Linear(in_features=4096, out_features=19, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lr(optimizer):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        return param_group['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def character_error_rate(preds, labels):\n",
    "    assert len(preds) == len(labels)\n",
    "    errors = 0\n",
    "    for pred, label in zip(preds, labels):\n",
    "        for p, l in zip(pred, label):\n",
    "            errors += int(p != l)\n",
    "    return errors / (len(labels) * len(labels[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model):\n",
    "    \n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    total_val_loss = 0\n",
    "    cer, cer_p = 0, 0\n",
    "    CER = CharErrorRate()\n",
    "    for data, targets in train_loader:\n",
    "        \n",
    "        data, targets = data.to(device), targets.to(device)\n",
    "        \n",
    "        output = model(data)\n",
    "        optim.zero_grad()\n",
    "        loss = criterion(output, targets)\n",
    "        loss.backward()\n",
    "\n",
    "        # torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n",
    "        optim.step()\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for data, targets in test_loader:\n",
    "            \n",
    "            data, targets = data.to(device), targets.to(device)\n",
    "            \n",
    "            preds = model(data)\n",
    "            val_loss = criterion(preds, targets)\n",
    "            total_val_loss += val_loss.item()\n",
    "            labels = alphabet.decode(targets)\n",
    "            pred_labels = alphabet.decode(preds)\n",
    "            cer_p += CER(pred_labels, labels)\n",
    "            cer += character_error_rate(pred_labels, labels)\n",
    "            \n",
    "    \n",
    "    total_loss /= len(train_loader)\n",
    "    total_val_loss /= len(test_loader)\n",
    "    cer /= len(test_loader)\n",
    "    cer_p /= len(test_loader)\n",
    "    \n",
    "    scheduler.step(total_val_loss)\n",
    "    \n",
    "    print('[Epoch {:3d}]:  lr {:02.6f} | train loss {:5.5f} | val loss {:5.5f} | val CER {:5.5f} | val CER(torch) {:5.5f}'.format(\n",
    "                epoch, get_lr(optim), total_loss, total_val_loss, cer, cer_p))\n",
    "    return total_loss, total_val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_curve_train, loss_curve_test = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch   1]:  lr 0.000200 | train loss 0.26620 | val loss 0.17044 | val CER 0.52455 | val CER(torch) 0.52455\n",
      "[Epoch   2]:  lr 0.000200 | train loss 0.11973 | val loss 0.10561 | val CER 0.31909 | val CER(torch) 0.31909\n",
      "[Epoch   3]:  lr 0.000200 | train loss 0.07662 | val loss 0.09537 | val CER 0.31545 | val CER(torch) 0.31545\n",
      "[Epoch   4]:  lr 0.000200 | train loss 0.07047 | val loss 0.06740 | val CER 0.19318 | val CER(torch) 0.19318\n",
      "[Epoch   5]:  lr 0.000200 | train loss 0.06149 | val loss 0.07130 | val CER 0.21000 | val CER(torch) 0.21000\n",
      "[Epoch   6]:  lr 0.000200 | train loss 0.05729 | val loss 0.06108 | val CER 0.17364 | val CER(torch) 0.17364\n",
      "[Epoch   7]:  lr 0.000200 | train loss 0.04939 | val loss 0.05630 | val CER 0.15591 | val CER(torch) 0.15591\n",
      "[Epoch   8]:  lr 0.000200 | train loss 0.04941 | val loss 0.07120 | val CER 0.16864 | val CER(torch) 0.16864\n",
      "[Epoch   9]:  lr 0.000200 | train loss 0.05209 | val loss 0.06573 | val CER 0.14864 | val CER(torch) 0.14864\n",
      "[Epoch  10]:  lr 0.000200 | train loss 0.04735 | val loss 0.05513 | val CER 0.09409 | val CER(torch) 0.09409\n",
      "[Epoch  11]:  lr 0.000200 | train loss 0.04572 | val loss 0.06503 | val CER 0.14045 | val CER(torch) 0.14045\n",
      "[Epoch  12]:  lr 0.000200 | train loss 0.04666 | val loss 0.06091 | val CER 0.12273 | val CER(torch) 0.12273\n",
      "[Epoch  13]:  lr 0.000200 | train loss 0.05065 | val loss 0.06484 | val CER 0.15318 | val CER(torch) 0.15318\n",
      "[Epoch  14]:  lr 0.000200 | train loss 0.04953 | val loss 0.06074 | val CER 0.12727 | val CER(torch) 0.12727\n",
      "[Epoch  15]:  lr 0.000200 | train loss 0.04458 | val loss 0.05557 | val CER 0.11773 | val CER(torch) 0.11773\n",
      "[Epoch  16]:  lr 0.000200 | train loss 0.04691 | val loss 0.05650 | val CER 0.13182 | val CER(torch) 0.13182\n",
      "Epoch 00017: reducing learning rate of group 0 to 1.0000e-04.\n",
      "[Epoch  17]:  lr 0.000100 | train loss 0.04725 | val loss 0.05690 | val CER 0.11545 | val CER(torch) 0.11545\n",
      "[Epoch  18]:  lr 0.000100 | train loss 0.04230 | val loss 0.05108 | val CER 0.08682 | val CER(torch) 0.08682\n",
      "[Epoch  19]:  lr 0.000100 | train loss 0.04035 | val loss 0.04656 | val CER 0.06455 | val CER(torch) 0.06455\n",
      "[Epoch  20]:  lr 0.000100 | train loss 0.03977 | val loss 0.04745 | val CER 0.06591 | val CER(torch) 0.06591\n",
      "[Epoch  21]:  lr 0.000100 | train loss 0.03953 | val loss 0.04691 | val CER 0.06045 | val CER(torch) 0.06045\n",
      "[Epoch  22]:  lr 0.000100 | train loss 0.03965 | val loss 0.04685 | val CER 0.05727 | val CER(torch) 0.05727\n",
      "[Epoch  23]:  lr 0.000100 | train loss 0.03965 | val loss 0.04741 | val CER 0.05773 | val CER(torch) 0.05773\n",
      "[Epoch  24]:  lr 0.000100 | train loss 0.03955 | val loss 0.04688 | val CER 0.05182 | val CER(torch) 0.05182\n",
      "[Epoch  25]:  lr 0.000100 | train loss 0.03936 | val loss 0.04710 | val CER 0.05864 | val CER(torch) 0.05864\n",
      "Epoch 00026: reducing learning rate of group 0 to 5.0000e-05.\n",
      "[Epoch  26]:  lr 0.000050 | train loss 0.03948 | val loss 0.04712 | val CER 0.05500 | val CER(torch) 0.05500\n",
      "[Epoch  27]:  lr 0.000050 | train loss 0.03939 | val loss 0.04731 | val CER 0.05182 | val CER(torch) 0.05182\n",
      "[Epoch  28]:  lr 0.000050 | train loss 0.03923 | val loss 0.04724 | val CER 0.05864 | val CER(torch) 0.05864\n",
      "[Epoch  29]:  lr 0.000050 | train loss 0.03925 | val loss 0.04743 | val CER 0.05182 | val CER(torch) 0.05182\n",
      "[Epoch  30]:  lr 0.000050 | train loss 0.03929 | val loss 0.04722 | val CER 0.05182 | val CER(torch) 0.05182\n",
      "[Epoch  31]:  lr 0.000050 | train loss 0.03911 | val loss 0.04778 | val CER 0.05545 | val CER(torch) 0.05545\n",
      "[Epoch  32]:  lr 0.000050 | train loss 0.03927 | val loss 0.04746 | val CER 0.05455 | val CER(torch) 0.05455\n",
      "Epoch 00033: reducing learning rate of group 0 to 2.5000e-05.\n",
      "[Epoch  33]:  lr 0.000025 | train loss 0.03927 | val loss 0.04762 | val CER 0.05773 | val CER(torch) 0.05773\n",
      "[Epoch  34]:  lr 0.000025 | train loss 0.03933 | val loss 0.04780 | val CER 0.05864 | val CER(torch) 0.05864\n",
      "[Epoch  35]:  lr 0.000025 | train loss 0.03929 | val loss 0.04762 | val CER 0.05591 | val CER(torch) 0.05591\n",
      "[Epoch  36]:  lr 0.000025 | train loss 0.03921 | val loss 0.04737 | val CER 0.05273 | val CER(torch) 0.05273\n",
      "[Epoch  37]:  lr 0.000025 | train loss 0.03926 | val loss 0.04774 | val CER 0.05591 | val CER(torch) 0.05591\n",
      "[Epoch  38]:  lr 0.000025 | train loss 0.03921 | val loss 0.04779 | val CER 0.05864 | val CER(torch) 0.05864\n",
      "[Epoch  39]:  lr 0.000025 | train loss 0.03932 | val loss 0.04764 | val CER 0.05364 | val CER(torch) 0.05364\n",
      "Epoch 00040: reducing learning rate of group 0 to 1.2500e-05.\n",
      "[Epoch  40]:  lr 0.000012 | train loss 0.03937 | val loss 0.04771 | val CER 0.05636 | val CER(torch) 0.05636\n",
      "[Epoch  41]:  lr 0.000012 | train loss 0.03932 | val loss 0.04805 | val CER 0.05682 | val CER(torch) 0.05682\n",
      "[Epoch  42]:  lr 0.000012 | train loss 0.03937 | val loss 0.04763 | val CER 0.05409 | val CER(torch) 0.05409\n",
      "[Epoch  43]:  lr 0.000012 | train loss 0.03950 | val loss 0.04785 | val CER 0.05455 | val CER(torch) 0.05455\n",
      "[Epoch  44]:  lr 0.000012 | train loss 0.03926 | val loss 0.04787 | val CER 0.05545 | val CER(torch) 0.05545\n",
      "[Epoch  45]:  lr 0.000012 | train loss 0.03952 | val loss 0.04796 | val CER 0.05455 | val CER(torch) 0.05455\n",
      "[Epoch  46]:  lr 0.000012 | train loss 0.03925 | val loss 0.04799 | val CER 0.05545 | val CER(torch) 0.05545\n",
      "Epoch 00047: reducing learning rate of group 0 to 6.2500e-06.\n",
      "[Epoch  47]:  lr 0.000006 | train loss 0.03920 | val loss 0.04796 | val CER 0.05364 | val CER(torch) 0.05364\n",
      "[Epoch  48]:  lr 0.000006 | train loss 0.03914 | val loss 0.04796 | val CER 0.05364 | val CER(torch) 0.05364\n",
      "[Epoch  49]:  lr 0.000006 | train loss 0.03931 | val loss 0.04796 | val CER 0.05455 | val CER(torch) 0.05455\n",
      "[Epoch  50]:  lr 0.000006 | train loss 0.03932 | val loss 0.04785 | val CER 0.05091 | val CER(torch) 0.05091\n",
      "[Epoch  51]:  lr 0.000006 | train loss 0.03920 | val loss 0.04796 | val CER 0.05364 | val CER(torch) 0.05364\n",
      "[Epoch  52]:  lr 0.000006 | train loss 0.03925 | val loss 0.04784 | val CER 0.05364 | val CER(torch) 0.05364\n",
      "[Epoch  53]:  lr 0.000006 | train loss 0.03925 | val loss 0.04761 | val CER 0.05864 | val CER(torch) 0.05864\n",
      "Epoch 00054: reducing learning rate of group 0 to 3.1250e-06.\n",
      "[Epoch  54]:  lr 0.000003 | train loss 0.03931 | val loss 0.04764 | val CER 0.05182 | val CER(torch) 0.05182\n",
      "[Epoch  55]:  lr 0.000003 | train loss 0.03925 | val loss 0.04745 | val CER 0.05364 | val CER(torch) 0.05364\n",
      "[Epoch  56]:  lr 0.000003 | train loss 0.03914 | val loss 0.04765 | val CER 0.05455 | val CER(torch) 0.05455\n",
      "[Epoch  57]:  lr 0.000003 | train loss 0.03927 | val loss 0.04776 | val CER 0.05500 | val CER(torch) 0.05500\n",
      "[Epoch  58]:  lr 0.000003 | train loss 0.03933 | val loss 0.04755 | val CER 0.05455 | val CER(torch) 0.05455\n",
      "[Epoch  59]:  lr 0.000003 | train loss 0.03925 | val loss 0.04804 | val CER 0.05273 | val CER(torch) 0.05273\n",
      "[Epoch  60]:  lr 0.000003 | train loss 0.03914 | val loss 0.04785 | val CER 0.05000 | val CER(torch) 0.05000\n",
      "Epoch 00061: reducing learning rate of group 0 to 1.5625e-06.\n",
      "[Epoch  61]:  lr 0.000002 | train loss 0.03938 | val loss 0.04792 | val CER 0.05636 | val CER(torch) 0.05636\n",
      "[Epoch  62]:  lr 0.000002 | train loss 0.03936 | val loss 0.04784 | val CER 0.05364 | val CER(torch) 0.05364\n",
      "[Epoch  63]:  lr 0.000002 | train loss 0.03914 | val loss 0.04783 | val CER 0.05273 | val CER(torch) 0.05273\n",
      "[Epoch  64]:  lr 0.000002 | train loss 0.03931 | val loss 0.04776 | val CER 0.05682 | val CER(torch) 0.05682\n",
      "[Epoch  65]:  lr 0.000002 | train loss 0.03908 | val loss 0.04781 | val CER 0.05864 | val CER(torch) 0.05864\n",
      "[Epoch  66]:  lr 0.000002 | train loss 0.03919 | val loss 0.04768 | val CER 0.05500 | val CER(torch) 0.05500\n",
      "[Epoch  67]:  lr 0.000002 | train loss 0.03933 | val loss 0.04783 | val CER 0.05545 | val CER(torch) 0.05545\n",
      "Epoch 00068: reducing learning rate of group 0 to 7.8125e-07.\n",
      "[Epoch  68]:  lr 0.000001 | train loss 0.03925 | val loss 0.04786 | val CER 0.05455 | val CER(torch) 0.05455\n",
      "[Epoch  69]:  lr 0.000001 | train loss 0.03919 | val loss 0.04772 | val CER 0.05364 | val CER(torch) 0.05364\n",
      "[Epoch  70]:  lr 0.000001 | train loss 0.03930 | val loss 0.04758 | val CER 0.05455 | val CER(torch) 0.05455\n",
      "[Epoch  71]:  lr 0.000001 | train loss 0.03913 | val loss 0.04761 | val CER 0.05364 | val CER(torch) 0.05364\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch  72]:  lr 0.000001 | train loss 0.03925 | val loss 0.04769 | val CER 0.05455 | val CER(torch) 0.05455\n",
      "[Epoch  73]:  lr 0.000001 | train loss 0.03925 | val loss 0.04814 | val CER 0.05364 | val CER(torch) 0.05364\n",
      "[Epoch  74]:  lr 0.000001 | train loss 0.03931 | val loss 0.04800 | val CER 0.05273 | val CER(torch) 0.05273\n",
      "Epoch 00075: reducing learning rate of group 0 to 3.9062e-07.\n",
      "[Epoch  75]:  lr 0.000000 | train loss 0.03925 | val loss 0.04770 | val CER 0.05455 | val CER(torch) 0.05455\n",
      "[Epoch  76]:  lr 0.000000 | train loss 0.03919 | val loss 0.04774 | val CER 0.05273 | val CER(torch) 0.05273\n",
      "[Epoch  77]:  lr 0.000000 | train loss 0.03925 | val loss 0.04784 | val CER 0.05682 | val CER(torch) 0.05682\n",
      "[Epoch  78]:  lr 0.000000 | train loss 0.03919 | val loss 0.04760 | val CER 0.05273 | val CER(torch) 0.05273\n",
      "[Epoch  79]:  lr 0.000000 | train loss 0.03919 | val loss 0.04800 | val CER 0.05500 | val CER(torch) 0.05500\n",
      "[Epoch  80]:  lr 0.000000 | train loss 0.03957 | val loss 0.04767 | val CER 0.05273 | val CER(torch) 0.05273\n",
      "[Epoch  81]:  lr 0.000000 | train loss 0.03925 | val loss 0.04794 | val CER 0.05364 | val CER(torch) 0.05364\n",
      "Epoch 00082: reducing learning rate of group 0 to 1.9531e-07.\n",
      "[Epoch  82]:  lr 0.000000 | train loss 0.03938 | val loss 0.04800 | val CER 0.05364 | val CER(torch) 0.05364\n",
      "[Epoch  83]:  lr 0.000000 | train loss 0.03932 | val loss 0.04805 | val CER 0.05364 | val CER(torch) 0.05364\n",
      "[Epoch  84]:  lr 0.000000 | train loss 0.03930 | val loss 0.04799 | val CER 0.05455 | val CER(torch) 0.05455\n",
      "[Epoch  85]:  lr 0.000000 | train loss 0.03925 | val loss 0.04797 | val CER 0.05636 | val CER(torch) 0.05636\n",
      "[Epoch  86]:  lr 0.000000 | train loss 0.03913 | val loss 0.04798 | val CER 0.05364 | val CER(torch) 0.05364\n",
      "[Epoch  87]:  lr 0.000000 | train loss 0.03919 | val loss 0.04796 | val CER 0.05500 | val CER(torch) 0.05500\n",
      "[Epoch  88]:  lr 0.000000 | train loss 0.03925 | val loss 0.04776 | val CER 0.05364 | val CER(torch) 0.05364\n",
      "Epoch 00089: reducing learning rate of group 0 to 9.7656e-08.\n",
      "[Epoch  89]:  lr 0.000000 | train loss 0.03908 | val loss 0.04761 | val CER 0.05364 | val CER(torch) 0.05364\n",
      "[Epoch  90]:  lr 0.000000 | train loss 0.03925 | val loss 0.04801 | val CER 0.05273 | val CER(torch) 0.05273\n",
      "[Epoch  91]:  lr 0.000000 | train loss 0.03913 | val loss 0.04814 | val CER 0.05545 | val CER(torch) 0.05545\n",
      "[Epoch  92]:  lr 0.000000 | train loss 0.03919 | val loss 0.04794 | val CER 0.05364 | val CER(torch) 0.05364\n",
      "[Epoch  93]:  lr 0.000000 | train loss 0.03930 | val loss 0.04812 | val CER 0.05455 | val CER(torch) 0.05455\n",
      "[Epoch  94]:  lr 0.000000 | train loss 0.03925 | val loss 0.04796 | val CER 0.05364 | val CER(torch) 0.05364\n",
      "[Epoch  95]:  lr 0.000000 | train loss 0.03925 | val loss 0.04794 | val CER 0.05455 | val CER(torch) 0.05455\n",
      "Epoch 00096: reducing learning rate of group 0 to 4.8828e-08.\n",
      "[Epoch  96]:  lr 0.000000 | train loss 0.03913 | val loss 0.04806 | val CER 0.05455 | val CER(torch) 0.05455\n",
      "[Epoch  97]:  lr 0.000000 | train loss 0.03925 | val loss 0.04787 | val CER 0.05364 | val CER(torch) 0.05364\n",
      "[Epoch  98]:  lr 0.000000 | train loss 0.03925 | val loss 0.04764 | val CER 0.05364 | val CER(torch) 0.05364\n",
      "[Epoch  99]:  lr 0.000000 | train loss 0.03931 | val loss 0.04799 | val CER 0.05273 | val CER(torch) 0.05273\n",
      "[Epoch 100]:  lr 0.000000 | train loss 0.03930 | val loss 0.04803 | val CER 0.05273 | val CER(torch) 0.05273\n",
      "CPU times: user 7min 39s, sys: 46.9 s, total: 8min 25s\n",
      "Wall time: 8min 46s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for epoch in range(1, 101):\n",
    "    train_loss, test_loss = train(model)\n",
    "    loss_curve_train.append(train_loss)\n",
    "    loss_curve_test.append(test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize loss\n",
    "plt.figure(figsize=(10, 8))\n",
    "    \n",
    "plt.title(\"Training loss\")\n",
    "plt.xlabel(\"#epoch\")\n",
    "plt.ylabel(\"loss\")\n",
    "\n",
    "plt.plot(loss_curve_train, label='train')\n",
    "plt.plot(loss_curve_test, label='test')\n",
    "\n",
    "\n",
    "#plt.yscale('log',base=2)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict, Counter\n",
    "\n",
    "val_loader = DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=4)\n",
    "\n",
    "im_by_cer = defaultdict(list)\n",
    "cnt = Counter()\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for data, target in val_loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        preds = model(data)\n",
    "        label = alphabet.decode(target)[0]\n",
    "        pred_label = alphabet.decode(preds)[0]\n",
    "        cer = character_error_rate(pred_label, label)\n",
    "        im_by_cer[cer].append((label, pred_label))\n",
    "        cnt[cer] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0.0: 163, 0.2: 44, 0.4: 7})\n"
     ]
    }
   ],
   "source": [
    "print(cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRUE        PRED        ERROR\n",
      "--------------------------------\n",
      "xemyg       xenyg    {m}--->{n}\n",
      "n265y       n266y    {5}--->{6}\n",
      "24f6w       24f5w    {6}--->{5}\n",
      "8gecm       8gecn    {m}--->{n}\n",
      "n5w5g       n5w5p    {g}--->{p}\n",
      "n2gmg       n2gng    {m}--->{n}\n",
      "pnnwy       pnnny    {w}--->{n}\n",
      "gc277       gc777    {2}--->{7}\n",
      "e25xg       e25yg    {x}--->{y}\n",
      "6pwcn       6pwcm    {n}--->{m}\n",
      "c86md       c86nd    {m}--->{n}\n",
      "pme86       pne86    {m}--->{n}\n",
      "bm3p8       bn3p8    {m}--->{n}\n",
      "7gp47       7gg47    {p}--->{g}\n",
      "4nc37       4nc57    {3}--->{5}\n",
      "n7meb       n7neb    {m}--->{n}\n",
      "gdng3       gdmg3    {n}--->{m}\n",
      "wddcp       wgdcp    {d}--->{g}\n",
      "cm6yb       cn6yb    {m}--->{n}\n",
      "n5n8b       n5n8p    {b}--->{p}\n",
      "xxbm5       xxbn5    {m}--->{n}\n",
      "m4g8g       n4g8g    {m}--->{n}\n",
      "3x5fm       3x5fn    {m}--->{n}\n",
      "7m8px       7n8px    {m}--->{n}\n",
      "5f3gf       5f3nf    {g}--->{n}\n",
      "excmn       excnn    {m}--->{n}\n",
      "46mbm       46nbm    {m}--->{n}\n",
      "bc8nf       bc8mf    {n}--->{m}\n",
      "5p8fm       5p8fn    {m}--->{n}\n",
      "5mf7c       5nf7c    {m}--->{n}\n",
      "e84n2       e84m2    {n}--->{m}\n",
      "gwn53       gnn53    {w}--->{n}\n",
      "nm248       nn248    {m}--->{n}\n",
      "p6mn8       p6mm8    {n}--->{m}\n",
      "yfdn7       yfdm7    {n}--->{m}\n",
      "f753f       f75df    {3}--->{d}\n",
      "ygenn       ygpnn    {e}--->{p}\n",
      "pgmn2       pgmm2    {n}--->{m}\n",
      "w6ny4       w6my4    {n}--->{m}\n",
      "gd4mf       gd4nf    {m}--->{n}\n",
      "nn6mg       nn6wg    {m}--->{w}\n",
      "6cwxe       6pwxe    {c}--->{p}\n",
      "7yf62       7yf52    {6}--->{5}\n",
      "ep85x       cp85x    {e}--->{c}\n",
      "dnmd8       gpmd8    {d, n}--->{g, p}\n",
      "gpnxn       gpmyn    {n, x}--->{m, y}\n",
      "wce5n       wxe5m    {c, n}--->{x, m}\n",
      "2mpnn       2mpmm    {n, n}--->{m, m}\n",
      "c2fb7       e2fw7    {c, b}--->{e, w}\n",
      "fncnb       fncdp    {n, b}--->{d, p}\n",
      "7pn5g       7pn6p    {5, g}--->{p, 6}\n"
     ]
    }
   ],
   "source": [
    "from multiset import Multiset\n",
    "\n",
    "print('TRUE        PRED        ERROR')\n",
    "print('--------------------------------')\n",
    "for cer in cnt.keys():\n",
    "    if cer == 0.: continue\n",
    "    for true_lbl, pred_lbl in im_by_cer[cer]:\n",
    "        pred_err_smb = Multiset(pred_lbl) - Multiset(true_lbl)\n",
    "        true_err_smb = Multiset(true_lbl) - Multiset(pred_lbl)\n",
    "        print(f'{true_lbl}       {pred_lbl}    {true_err_smb}--->{pred_err_smb}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##### ,     -  'n'  'm', 'c'  'e', '6'  '8'  .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
