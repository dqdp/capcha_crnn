{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import random\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, ColorJitter, Compose, Normalize\n",
    "\n",
    "from torch import nn\n",
    "from torch.nn import Module\n",
    "from torch.nn import Conv2d\n",
    "from torch.nn import Linear\n",
    "from torch.nn import ReLU\n",
    "from torch.nn import LogSoftmax\n",
    "from torch.nn import BatchNorm2d\n",
    "from torch.nn import LSTM\n",
    "from torch import flatten\n",
    "from torchmetrics import CharErrorRate\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import CTCLoss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alphabet class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Alphabet(object):\n",
    "    def __init__(self, folder_path):\n",
    "        self.symbol2idx = {}\n",
    "        self.idx2symbol = []\n",
    "        self._len = 0\n",
    "        self.make_alphabet(folder_path)\n",
    "        \n",
    "    def add_symbol(self, s):\n",
    "        if s not in self.symbol2idx:\n",
    "            self.idx2symbol.append(s)\n",
    "            self.symbol2idx[s] = self._len\n",
    "            self._len += 1\n",
    "            \n",
    "    def make_alphabet(self, folder_path):\n",
    "        assert os.path.exists(folder_path)\n",
    "        for _, _, files in os.walk(folder_path):\n",
    "            for file_name in files:\n",
    "                file_name = file_name.split('.')[0]\n",
    "                for symbol in file_name:\n",
    "                    self.add_symbol(symbol)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self._len\n",
    "    \n",
    "    def encode(self, label):\n",
    "        ids = torch.zeros([len(label), len(self)], dtype=torch.float32)\n",
    "        for pos, symbol in enumerate(label):\n",
    "            ids[pos, self.symbol2idx[symbol]] = 1.\n",
    "        return ids\n",
    "    \n",
    "    def decode(self, ids):\n",
    "        idxs = ids.argmax(dim=2).tolist()\n",
    "        labels = [''.join([self.idx2symbol[i] for i in b]) for b in idxs]\n",
    "        return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dir = './samples/'\n",
    "\n",
    "alphabet = Alphabet(img_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, img_dir, transform=None, target_transform=None):\n",
    "        self.img_labels = []\n",
    "        for _, _, files in os.walk(img_dir):\n",
    "            for file_ in files:\n",
    "                self.img_labels.append(file_)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        filename = self.img_labels[idx]\n",
    "        img_path = os.path.join(self.img_dir, filename)\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        label = alphabet.encode(filename.split('.')[0])\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_files = []\n",
    "for _, _, files in os.walk(img_dir):\n",
    "    for file_ in files:\n",
    "        all_files.append(file_)\n",
    "        \n",
    "random.shuffle(all_files)\n",
    "border = int(0.8 * len(all_files))\n",
    "train_files = all_files[:border]\n",
    "test_files = all_files[border:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_dir = 'data/train/'\n",
    "test_data_dir = 'data/test/'\n",
    "\n",
    "if not os.path.exists(train_data_dir):\n",
    "    os.makedirs(train_data_dir)\n",
    "    for file in train_files:\n",
    "        shutil.copy(os.path.join(img_dir, file), train_data_dir)\n",
    "\n",
    "if not os.path.exists(test_data_dir):\n",
    "    os.makedirs(test_data_dir)\n",
    "    for file in test_files:\n",
    "        shutil.copy(os.path.join(img_dir, file), test_data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomImageDataset(img_dir=train_data_dir,\n",
    "                                   transform=Compose([\n",
    "                                            #ColorJitter(),\n",
    "                                            ToTensor(),\n",
    "                                            Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n",
    "                                   ]))\n",
    "\n",
    "test_dataset = CustomImageDataset(img_dir=test_data_dir,\n",
    "                                  transform=Compose([\n",
    "                                            ToTensor(),\n",
    "                                            Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n",
    "                                 ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find mean and std of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4305, 0.4305, 0.4305])\n",
      "tensor([0.6269, 0.6269, 0.6269])\n"
     ]
    }
   ],
   "source": [
    "nimages = 0\n",
    "mean = 0.0\n",
    "var = 0.0\n",
    "for i_batch, batch_target in enumerate(train_loader):\n",
    "    batch = batch_target[0]\n",
    "    # Rearrange batch to be the shape of [B, C, W * H]\n",
    "    batch = batch.view(batch.size(0), batch.size(1), -1)\n",
    "    # Update total number of images\n",
    "    nimages += batch.size(0)\n",
    "    # Compute mean and std here\n",
    "    mean += batch.mean(2).sum(0) \n",
    "    var += batch.var(2).sum(0)\n",
    "\n",
    "mean /= nimages\n",
    "var /= nimages\n",
    "std = torch.sqrt(var)\n",
    "\n",
    "print(mean)\n",
    "print(std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomImageDataset(img_dir=train_data_dir,\n",
    "                                   transform=Compose([\n",
    "                                            #ColorJitter(),\n",
    "                                            ToTensor(),\n",
    "                                            Normalize(mean=[0.4304, 0.4304, 0.4304], std=[0.6269, 0.6269, 0.6269]),\n",
    "                                   ]))\n",
    "\n",
    "test_dataset = CustomImageDataset(img_dir=test_data_dir,\n",
    "                                  transform=Compose([\n",
    "                                            ToTensor(),\n",
    "                                            Normalize(mean=[0.4304, 0.4304, 0.4304], std=[0.6269, 0.6269, 0.6269]),\n",
    "                                 ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bidirectional_LSTM(torch.nn.Module):\n",
    "    def __init__(self, class_num, hidden_unit):\n",
    "        super(Bidirectional_LSTM, self).__init__()\n",
    "        self.LSTM1 = torch.nn.LSTM(1024, hidden_unit, bidirectional=True)\n",
    "        self.embedding1 = torch.nn.Linear(hidden_unit * 2, 1024)\n",
    "        self.LSTM2 = torch.nn.LSTM(1024, hidden_unit, bidirectional=True)\n",
    "        self.embedding2 = torch.nn.Linear(hidden_unit * 2, class_num)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.LSTM1(x)   # LSTM output: output, (h_n, c_n)\n",
    "        T, b, h = x[0].size()   # x[0]: (seq_len, batch, num_directions * hidden_size)\n",
    "        x = self.embedding1(x[0].view(T * b, h))  # pytorch view() reshape as [T * b, nOut]\n",
    "        x = x.view(T, b, -1)  # [seq_len, b, 512]\n",
    "        x = self.LSTM2(x)\n",
    "        T, b, h = x[0].size()\n",
    "        x = self.embedding2(x[0].view(T * b, h))\n",
    "        x = x.view(T, b, -1)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CapchaNet(Module):\n",
    "    def __init__(self, alphabet_len):\n",
    "        super(CapchaNet, self).__init__()\n",
    "        \n",
    "        self.conv1 = Conv2d(3, 64, (3, 3), stride=2) # 99x24\n",
    "        self.bn1 = BatchNorm2d(64)\n",
    "        self.conv2 = Conv2d(64, 128, (3, 3), stride=2) # 48x11\n",
    "        self.bn2 = BatchNorm2d(128)\n",
    "        self.conv3 = Conv2d(128, 256, (3, 3), stride=2) # 23x5\n",
    "        self.bn3 = BatchNorm2d(256)\n",
    "        self.conv4 = Conv2d(256, 512, (3, 3), stride=2) # 11x2\n",
    "        self.bn4 = BatchNorm2d(512)\n",
    "        self.conv5 = Conv2d(512, 1024, (2, 2), stride=(1, 2)) # 5X1\n",
    "        self.bn5 = BatchNorm2d(1024)\n",
    "        # self.glob_pool = AdaptiveAvgPool2d((1,1)) \n",
    "        self.rnn = Bidirectional_LSTM(alphabet_len, 1024)\n",
    "        # self.fc1 = Linear(9 * 5 * 512, 512)\n",
    "        # self.fc2 = Linear(512, alphabet_len * 5)\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.bn1(F.relu(self.conv1(x)))\n",
    "        x = self.bn2(F.relu(self.conv2(x)))\n",
    "        x = self.bn3(F.relu(self.conv3(x)))\n",
    "        x = self.bn4(F.relu(self.conv4(x)))\n",
    "        x = self.bn5(F.relu(self.conv5(x)))\n",
    "        # x = self.glob_pool(x)\n",
    "        # x = flatten(x, start_dim=1)\n",
    "        \n",
    "        x = x.squeeze(2)  # remove h dimension\n",
    "        x = x.permute(2, 0, 1)  # [w, b, c] = [seq_len, batch, input_size]\n",
    "        x = self.rnn(x)\n",
    "        x = x.permute(1, 0, 2)\n",
    "        # x = F.relu(self.fc1(x))\n",
    "        # x = self.fc2(x)\n",
    "        # x = x.view(-1, 5, 19)\n",
    "        output = F.log_softmax(x, dim=2) \n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import math\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "ntokens = len(alphabet)\n",
    "model = CapchaNet(ntokens)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "grad_clip = 0.1\n",
    "lr = torch.tensor(1e-3)\n",
    "optim = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "scheduler = lr_scheduler.ReduceLROnPlateau(optim, mode='min',\n",
    "                                           factor=0.4, patience=3, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lr(optimizer):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        return param_group['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def character_error_rate(preds, labels):\n",
    "    assert len(preds) == len(labels)\n",
    "    errors = 0\n",
    "    for pred, label in zip(preds, labels):\n",
    "        for p, l in zip(pred, label):\n",
    "            errors += int(p != l)\n",
    "    return errors / (len(labels) * len(labels[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model):\n",
    "    \n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    total_val_loss = 0\n",
    "    cer, cer_p = 0, 0\n",
    "    CER = CharErrorRate()\n",
    "    for batch, (data, targets) in enumerate(train_loader):\n",
    "        \n",
    "        output = model(data)\n",
    "        optim.zero_grad()\n",
    "        loss = criterion(output, targets)\n",
    "        loss.backward()\n",
    "\n",
    "        # torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n",
    "        optim.step()\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for data, targets in test_loader:\n",
    "            preds = model(data)\n",
    "            val_loss = criterion(preds, targets)\n",
    "            total_val_loss += val_loss.item()\n",
    "            labels = alphabet.decode(targets)\n",
    "            pred_labels = alphabet.decode(preds)\n",
    "            cer_p += CER(pred_labels, labels)\n",
    "            cer += character_error_rate(pred_labels, labels)\n",
    "            \n",
    "    \n",
    "    total_loss /= len(train_loader)\n",
    "    total_val_loss /= len(test_loader)\n",
    "    cer /= len(test_loader)\n",
    "    cer_p /= len(test_loader)\n",
    "    \n",
    "    scheduler.step(total_val_loss)\n",
    "    \n",
    "    print('[Epoch {:3d}]:  lr {:02.6f} | train loss {:5.5f} | val loss {:5.5f} | val CER {:5.5f} | val CER(torch) {:5.5f}'.format(\n",
    "                epoch, get_lr(optim), total_loss, total_val_loss, cer, cer_p))\n",
    "    return total_loss, total_val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_curve_train, loss_curve_test = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch   1]:  lr 0.001000 | train loss 0.26901 | val loss 0.29594 | val CER 0.83023 | val CER(torch) 0.83023\n",
      "[Epoch   2]:  lr 0.001000 | train loss 0.11948 | val loss 0.12212 | val CER 0.42694 | val CER(torch) 0.42694\n",
      "[Epoch   3]:  lr 0.001000 | train loss 0.08094 | val loss 0.07452 | val CER 0.25542 | val CER(torch) 0.25542\n",
      "[Epoch   4]:  lr 0.001000 | train loss 0.06473 | val loss 0.06164 | val CER 0.19603 | val CER(torch) 0.19603\n",
      "[Epoch   5]:  lr 0.001000 | train loss 0.05476 | val loss 0.05753 | val CER 0.14289 | val CER(torch) 0.14289\n",
      "[Epoch   6]:  lr 0.001000 | train loss 0.05600 | val loss 0.05424 | val CER 0.12148 | val CER(torch) 0.12148\n",
      "[Epoch   7]:  lr 0.001000 | train loss 0.04862 | val loss 0.04956 | val CER 0.10632 | val CER(torch) 0.10632\n",
      "[Epoch   8]:  lr 0.001000 | train loss 0.05002 | val loss 0.05106 | val CER 0.12076 | val CER(torch) 0.12076\n",
      "[Epoch   9]:  lr 0.001000 | train loss 0.05257 | val loss 0.05712 | val CER 0.14445 | val CER(torch) 0.14445\n",
      "[Epoch  10]:  lr 0.001000 | train loss 0.04914 | val loss 0.05033 | val CER 0.11419 | val CER(torch) 0.11419\n",
      "[Epoch  11]:  lr 0.001000 | train loss 0.04581 | val loss 0.04703 | val CER 0.08612 | val CER(torch) 0.08612\n",
      "[Epoch  12]:  lr 0.001000 | train loss 0.04439 | val loss 0.04430 | val CER 0.05808 | val CER(torch) 0.05808\n",
      "[Epoch  13]:  lr 0.001000 | train loss 0.04121 | val loss 0.04374 | val CER 0.05287 | val CER(torch) 0.05287\n",
      "[Epoch  14]:  lr 0.001000 | train loss 0.04147 | val loss 0.04465 | val CER 0.06069 | val CER(torch) 0.06069\n",
      "[Epoch  15]:  lr 0.001000 | train loss 0.04207 | val loss 0.04517 | val CER 0.05553 | val CER(torch) 0.05553\n",
      "[Epoch  16]:  lr 0.001000 | train loss 0.04505 | val loss 0.04991 | val CER 0.10451 | val CER(torch) 0.10451\n",
      "Epoch 00017: reducing learning rate of group 0 to 4.0000e-04.\n",
      "[Epoch  17]:  lr 0.000400 | train loss 0.04493 | val loss 0.04438 | val CER 0.07241 | val CER(torch) 0.07241\n",
      "[Epoch  18]:  lr 0.000400 | train loss 0.04077 | val loss 0.04175 | val CER 0.04881 | val CER(torch) 0.04881\n",
      "[Epoch  19]:  lr 0.000400 | train loss 0.03906 | val loss 0.04089 | val CER 0.03407 | val CER(torch) 0.03407\n",
      "[Epoch  20]:  lr 0.000400 | train loss 0.03878 | val loss 0.04079 | val CER 0.03042 | val CER(torch) 0.03042\n",
      "[Epoch  21]:  lr 0.000400 | train loss 0.03870 | val loss 0.04071 | val CER 0.02881 | val CER(torch) 0.02881\n",
      "[Epoch  22]:  lr 0.000400 | train loss 0.03868 | val loss 0.04064 | val CER 0.02777 | val CER(torch) 0.02777\n",
      "[Epoch  23]:  lr 0.000400 | train loss 0.03868 | val loss 0.04066 | val CER 0.02724 | val CER(torch) 0.02724\n",
      "[Epoch  24]:  lr 0.000400 | train loss 0.03866 | val loss 0.04059 | val CER 0.02672 | val CER(torch) 0.02672\n",
      "[Epoch  25]:  lr 0.000400 | train loss 0.03865 | val loss 0.04060 | val CER 0.02672 | val CER(torch) 0.02672\n",
      "[Epoch  26]:  lr 0.000400 | train loss 0.03864 | val loss 0.04054 | val CER 0.02464 | val CER(torch) 0.02464\n",
      "[Epoch  27]:  lr 0.000400 | train loss 0.03863 | val loss 0.04057 | val CER 0.02568 | val CER(torch) 0.02568\n",
      "[Epoch  28]:  lr 0.000400 | train loss 0.03864 | val loss 0.04053 | val CER 0.02568 | val CER(torch) 0.02568\n",
      "[Epoch  29]:  lr 0.000400 | train loss 0.03863 | val loss 0.04059 | val CER 0.02516 | val CER(torch) 0.02516\n",
      "Epoch 00030: reducing learning rate of group 0 to 1.6000e-04.\n",
      "[Epoch  30]:  lr 0.000160 | train loss 0.03863 | val loss 0.04055 | val CER 0.02568 | val CER(torch) 0.02568\n",
      "[Epoch  31]:  lr 0.000160 | train loss 0.03863 | val loss 0.04049 | val CER 0.02516 | val CER(torch) 0.02516\n",
      "[Epoch  32]:  lr 0.000160 | train loss 0.03864 | val loss 0.04054 | val CER 0.02464 | val CER(torch) 0.02464\n",
      "[Epoch  33]:  lr 0.000160 | train loss 0.03863 | val loss 0.04053 | val CER 0.02516 | val CER(torch) 0.02516\n",
      "[Epoch  34]:  lr 0.000160 | train loss 0.03860 | val loss 0.04052 | val CER 0.02568 | val CER(torch) 0.02568\n",
      "[Epoch  35]:  lr 0.000160 | train loss 0.03862 | val loss 0.04048 | val CER 0.02568 | val CER(torch) 0.02568\n",
      "[Epoch  36]:  lr 0.000160 | train loss 0.03861 | val loss 0.04047 | val CER 0.02464 | val CER(torch) 0.02464\n",
      "[Epoch  37]:  lr 0.000160 | train loss 0.03862 | val loss 0.04051 | val CER 0.02464 | val CER(torch) 0.02464\n",
      "[Epoch  38]:  lr 0.000160 | train loss 0.03861 | val loss 0.04059 | val CER 0.02568 | val CER(torch) 0.02568\n",
      "[Epoch  39]:  lr 0.000160 | train loss 0.03861 | val loss 0.04052 | val CER 0.02516 | val CER(torch) 0.02516\n",
      "Epoch 00040: reducing learning rate of group 0 to 6.4000e-05.\n",
      "[Epoch  40]:  lr 0.000064 | train loss 0.03861 | val loss 0.04058 | val CER 0.02412 | val CER(torch) 0.02412\n",
      "[Epoch  41]:  lr 0.000064 | train loss 0.03862 | val loss 0.04049 | val CER 0.02308 | val CER(torch) 0.02308\n",
      "[Epoch  42]:  lr 0.000064 | train loss 0.03863 | val loss 0.04054 | val CER 0.02412 | val CER(torch) 0.02412\n",
      "[Epoch  43]:  lr 0.000064 | train loss 0.03860 | val loss 0.04057 | val CER 0.02412 | val CER(torch) 0.02412\n",
      "[Epoch  44]:  lr 0.000064 | train loss 0.03860 | val loss 0.04046 | val CER 0.02464 | val CER(torch) 0.02464\n",
      "[Epoch  45]:  lr 0.000064 | train loss 0.03861 | val loss 0.04048 | val CER 0.02412 | val CER(torch) 0.02412\n",
      "[Epoch  46]:  lr 0.000064 | train loss 0.03860 | val loss 0.04046 | val CER 0.02464 | val CER(torch) 0.02464\n",
      "[Epoch  47]:  lr 0.000064 | train loss 0.03861 | val loss 0.04052 | val CER 0.02412 | val CER(torch) 0.02412\n",
      "Epoch 00048: reducing learning rate of group 0 to 2.5600e-05.\n",
      "[Epoch  48]:  lr 0.000026 | train loss 0.03860 | val loss 0.04050 | val CER 0.02360 | val CER(torch) 0.02360\n",
      "[Epoch  49]:  lr 0.000026 | train loss 0.03861 | val loss 0.04049 | val CER 0.02464 | val CER(torch) 0.02464\n",
      "[Epoch  50]:  lr 0.000026 | train loss 0.03860 | val loss 0.04045 | val CER 0.02412 | val CER(torch) 0.02412\n",
      "[Epoch  51]:  lr 0.000026 | train loss 0.03862 | val loss 0.04050 | val CER 0.02308 | val CER(torch) 0.02308\n",
      "[Epoch  52]:  lr 0.000026 | train loss 0.03859 | val loss 0.04049 | val CER 0.02412 | val CER(torch) 0.02412\n",
      "[Epoch  53]:  lr 0.000026 | train loss 0.03860 | val loss 0.04050 | val CER 0.02412 | val CER(torch) 0.02412\n",
      "Epoch 00054: reducing learning rate of group 0 to 1.0240e-05.\n",
      "[Epoch  54]:  lr 0.000010 | train loss 0.03860 | val loss 0.04046 | val CER 0.02308 | val CER(torch) 0.02308\n",
      "[Epoch  55]:  lr 0.000010 | train loss 0.03860 | val loss 0.04048 | val CER 0.02360 | val CER(torch) 0.02360\n",
      "[Epoch  56]:  lr 0.000010 | train loss 0.03861 | val loss 0.04052 | val CER 0.02412 | val CER(torch) 0.02412\n",
      "[Epoch  57]:  lr 0.000010 | train loss 0.03860 | val loss 0.04054 | val CER 0.02360 | val CER(torch) 0.02360\n",
      "Epoch 00058: reducing learning rate of group 0 to 4.0960e-06.\n",
      "[Epoch  58]:  lr 0.000004 | train loss 0.03860 | val loss 0.04048 | val CER 0.02360 | val CER(torch) 0.02360\n",
      "[Epoch  59]:  lr 0.000004 | train loss 0.03861 | val loss 0.04041 | val CER 0.02360 | val CER(torch) 0.02360\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 60):\n",
    "    train_loss, test_loss = train(model)\n",
    "    loss_curve_train.append(train_loss)\n",
    "    loss_curve_test.append(test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize loss\n",
    "plt.figure(figsize=(10, 8))\n",
    "    \n",
    "plt.title(\"Training loss\")\n",
    "plt.xlabel(\"#epoch\")\n",
    "plt.ylabel(\"loss\")\n",
    "\n",
    "plt.plot(loss_curve_train, label='train')\n",
    "plt.plot(loss_curve_test, label='test')\n",
    "\n",
    "\n",
    "#plt.yscale('log',base=2)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
