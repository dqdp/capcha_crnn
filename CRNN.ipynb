{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import random\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, ColorJitter, Compose, Normalize\n",
    "\n",
    "from torch import nn\n",
    "from torch.nn import Module\n",
    "from torch.nn import Conv2d\n",
    "from torch.nn import Linear\n",
    "from torch.nn import ReLU\n",
    "from torch.nn import LogSoftmax\n",
    "from torch.nn import BatchNorm2d\n",
    "from torch.nn import LSTM\n",
    "from torch import flatten\n",
    "from torchmetrics import CharErrorRate\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import CTCLoss\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alphabet class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Alphabet(object):\n",
    "    def __init__(self, folder_path):\n",
    "        self.symbol2idx = {}\n",
    "        self.idx2symbol = []\n",
    "        self._len = 0\n",
    "        self.make_alphabet(folder_path)\n",
    "        \n",
    "    def add_symbol(self, s):\n",
    "        if s not in self.symbol2idx:\n",
    "            self.idx2symbol.append(s)\n",
    "            self.symbol2idx[s] = self._len\n",
    "            self._len += 1\n",
    "            \n",
    "    def make_alphabet(self, folder_path):\n",
    "        assert os.path.exists(folder_path)\n",
    "        for _, _, files in os.walk(folder_path):\n",
    "            for file_name in files:\n",
    "                file_name = file_name.split('.')[0]\n",
    "                for symbol in file_name:\n",
    "                    self.add_symbol(symbol)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self._len\n",
    "    \n",
    "    def encode(self, label):\n",
    "        ids = torch.zeros([len(label), len(self)], dtype=torch.float32)\n",
    "        for pos, symbol in enumerate(label):\n",
    "            ids[pos, self.symbol2idx[symbol]] = 1.\n",
    "        return ids\n",
    "    \n",
    "    def decode(self, ids):\n",
    "        idxs = ids.argmax(dim=2).tolist()\n",
    "        labels = [''.join([self.idx2symbol[i] for i in b]) for b in idxs]\n",
    "        return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dir = './samples/'\n",
    "\n",
    "alphabet = Alphabet(img_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, img_dir, transform=None):\n",
    "        self.img_labels = []\n",
    "        for _, _, files in os.walk(img_dir):\n",
    "            for file_ in files:\n",
    "                self.img_labels.append(file_)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        filename = self.img_labels[idx]\n",
    "        img_path = os.path.join(self.img_dir, filename)\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        label = alphabet.encode(filename.split('.')[0])\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_files = []\n",
    "for _, _, files in os.walk(img_dir):\n",
    "    for file_ in files:\n",
    "        all_files.append(file_)\n",
    "        \n",
    "random.shuffle(all_files)\n",
    "border = int(0.8 * len(all_files))\n",
    "train_files = all_files[:border]\n",
    "test_files = all_files[border:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_dir = 'data/train/'\n",
    "test_data_dir = 'data/test/'\n",
    "\n",
    "if not os.path.exists(train_data_dir):\n",
    "    os.makedirs(train_data_dir)\n",
    "    for file in train_files:\n",
    "        shutil.copy(os.path.join(img_dir, file), train_data_dir)\n",
    "\n",
    "if not os.path.exists(test_data_dir):\n",
    "    os.makedirs(test_data_dir)\n",
    "    for file in test_files:\n",
    "        shutil.copy(os.path.join(img_dir, file), test_data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find mean and std of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CustomImageDataset(img_dir=train_data_dir,\n",
    "                                   transform=Compose([\n",
    "                                            ColorJitter(),\n",
    "                                            ToTensor(),\n",
    "                                   ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = DataLoader(dataset, batch_size=16, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.7151, 0.7151, 0.7151])\n",
      "tensor([0.3135, 0.3135, 0.3135])\n"
     ]
    }
   ],
   "source": [
    "nimages = 0\n",
    "mean = 0.0\n",
    "var = 0.0\n",
    "for i_batch, batch_target in enumerate(data_loader):\n",
    "    batch = batch_target[0]\n",
    "    # Rearrange batch to be the shape of [B, C, W * H]\n",
    "    batch = batch.view(batch.size(0), batch.size(1), -1)\n",
    "    # Update total number of images\n",
    "    nimages += batch.size(0)\n",
    "    # Compute mean and std here\n",
    "    mean += batch.mean(2).sum(0) \n",
    "    var += batch.var(2).sum(0)\n",
    "\n",
    "mean /= nimages\n",
    "var /= nimages\n",
    "std = torch.sqrt(var)\n",
    "\n",
    "print(mean)\n",
    "print(std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomImageDataset(img_dir=train_data_dir,\n",
    "                                   transform=Compose([\n",
    "                                            #ColorJitter(),\n",
    "                                            ToTensor(),\n",
    "                                            Normalize(mean=[0.7151, 0.7151, 0.7151], std=[0.3136, 0.3136, 0.3136]),\n",
    "                                   ]))\n",
    "\n",
    "test_dataset = CustomImageDataset(img_dir=test_data_dir,\n",
    "                                  transform=Compose([\n",
    "                                            ToTensor(),\n",
    "                                            Normalize(mean=[0.7151, 0.7151, 0.7151], std=[0.3136, 0.3136, 0.3136]),\n",
    "                                 ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=10, shuffle=True, num_workers=6)\n",
    "test_loader = DataLoader(test_dataset, batch_size=10, shuffle=False, num_workers=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bidirectional_LSTM(torch.nn.Module):\n",
    "    def __init__(self, class_num, hidden_unit):\n",
    "        super(Bidirectional_LSTM, self).__init__()\n",
    "        \n",
    "        self.LSTM1 = torch.nn.LSTM(2048, hidden_unit, bidirectional=True, dropout=0.2)\n",
    "        self.embedding1 = torch.nn.Linear(hidden_unit * 2, 2048)\n",
    "        self.LSTM2 = torch.nn.LSTM(2048, hidden_unit, bidirectional=True, dropout=0.2)\n",
    "        self.embedding2 = torch.nn.Linear(hidden_unit * 2, class_num)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.LSTM1(x)   # LSTM output: output, (h_n, c_n)\n",
    "        T, b, h = x[0].size()   # x[0]: (seq_len, batch, num_directions * hidden_size)\n",
    "        x = self.embedding1(x[0].view(T * b, h))  # pytorch view() reshape as [T * b, nOut]\n",
    "        x = x.view(T, b, -1)  # [seq_len, b, 512]\n",
    "        \n",
    "        x = self.LSTM2(x)\n",
    "        T, b, h = x[0].size()\n",
    "        x = self.embedding2(x[0].view(T * b, h))\n",
    "        x = x.view(T, b, -1)\n",
    "        \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CapchaNet(Module):\n",
    "    def __init__(self, alphabet_len):\n",
    "        super(CapchaNet, self).__init__()\n",
    "        \n",
    "        self.conv1 = Conv2d(3, 128, (3, 3), stride=2) # 99x24\n",
    "        self.bn1 = BatchNorm2d(128)\n",
    "        self.conv2 = Conv2d(128, 256, (3, 3), stride=2) # 48x11\n",
    "        self.bn2 = BatchNorm2d(256)\n",
    "        self.conv3 = Conv2d(256, 512, (3, 3), stride=2) # 23x5\n",
    "        self.bn3 = BatchNorm2d(512)\n",
    "        self.conv4 = Conv2d(512, 1024, (3, 3), stride=2) # 11x2\n",
    "        self.bn4 = BatchNorm2d(1024)\n",
    "        self.conv5 = Conv2d(1024, 2048, (2, 2), stride=(1, 2)) # 5X1\n",
    "        self.bn5 = BatchNorm2d(2048)\n",
    "        #self.conv6 = Conv2d(2048, 4096, (1, 1)) # 5X1\n",
    "        #self.bn6 = BatchNorm2d(4096)\n",
    "        self.rnn = Bidirectional_LSTM(alphabet_len, 2048)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.bn1(F.relu(self.conv1(x)))\n",
    "        x = self.bn2(F.relu(self.conv2(x)))\n",
    "        x = self.bn3(F.relu(self.conv3(x)))\n",
    "        x = self.bn4(F.relu(self.conv4(x)))\n",
    "        x = self.bn5(F.relu(self.conv5(x)))\n",
    "        #x = self.bn6(F.relu(self.conv6(x)))\n",
    "        \n",
    "        x = x.squeeze(2)  # remove h dimension\n",
    "        x = x.permute(2, 0, 1)  # [w, b, c] = [seq_len, batch, input_size]\n",
    "        x = self.rnn(x)\n",
    "        \n",
    "        x = x.permute(1, 0, 2)\n",
    "        output = F.log_softmax(x, dim=2)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alex/anaconda3/lib/python3.8/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "import math\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "ntokens = len(alphabet)\n",
    "model = CapchaNet(ntokens)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "grad_clip = 0.1\n",
    "lr = torch.tensor(2e-4)\n",
    "optim = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "scheduler = lr_scheduler.ReduceLROnPlateau(optim, mode='min',\n",
    "                                           factor=0.5, patience=7, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CapchaNet(\n",
       "  (conv1): Conv2d(3, 128, kernel_size=(3, 3), stride=(2, 2))\n",
       "  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv2): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2))\n",
       "  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv3): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2))\n",
       "  (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv4): Conv2d(512, 1024, kernel_size=(3, 3), stride=(2, 2))\n",
       "  (bn4): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv5): Conv2d(1024, 2048, kernel_size=(2, 2), stride=(1, 2))\n",
       "  (bn5): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (rnn): Bidirectional_LSTM(\n",
       "    (LSTM1): LSTM(2048, 2048, dropout=0.2, bidirectional=True)\n",
       "    (embedding1): Linear(in_features=4096, out_features=2048, bias=True)\n",
       "    (LSTM2): LSTM(2048, 2048, dropout=0.2, bidirectional=True)\n",
       "    (embedding2): Linear(in_features=4096, out_features=19, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lr(optimizer):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        return param_group['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def character_error_rate(preds, labels):\n",
    "    assert len(preds) == len(labels)\n",
    "    errors = 0\n",
    "    for pred, label in zip(preds, labels):\n",
    "        for p, l in zip(pred, label):\n",
    "            errors += int(p != l)\n",
    "    return errors / (len(labels) * len(labels[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model):\n",
    "    \n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    total_val_loss = 0\n",
    "    cer, cer_p = 0, 0\n",
    "    CER = CharErrorRate()\n",
    "    for data, targets in train_loader:\n",
    "        \n",
    "        data, targets = data.to(device), targets.to(device)\n",
    "        \n",
    "        output = model(data)\n",
    "        optim.zero_grad()\n",
    "        loss = criterion(output, targets)\n",
    "        loss.backward()\n",
    "\n",
    "        # torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n",
    "        optim.step()\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for data, targets in test_loader:\n",
    "            \n",
    "            data, targets = data.to(device), targets.to(device)\n",
    "            \n",
    "            preds = model(data)\n",
    "            val_loss = criterion(preds, targets)\n",
    "            total_val_loss += val_loss.item()\n",
    "            labels = alphabet.decode(targets)\n",
    "            pred_labels = alphabet.decode(preds)\n",
    "            cer_p += CER(pred_labels, labels)\n",
    "            cer += character_error_rate(pred_labels, labels)\n",
    "            \n",
    "    \n",
    "    total_loss /= len(train_loader)\n",
    "    total_val_loss /= len(test_loader)\n",
    "    cer /= len(test_loader)\n",
    "    cer_p /= len(test_loader)\n",
    "    \n",
    "    scheduler.step(total_val_loss)\n",
    "    \n",
    "    print('[Epoch {:3d}]:  lr {:02.6f} | train loss {:5.5f} | val loss {:5.5f} | val CER {:5.5f} | val CER(torch) {:5.5f}'.format(\n",
    "                epoch, get_lr(optim), total_loss, total_val_loss, cer, cer_p))\n",
    "    return total_loss, total_val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_curve_train, loss_curve_test = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch   1]:  lr 0.000200 | train loss 0.26846 | val loss 0.17000 | val CER 0.61182 | val CER(torch) 0.61182\n",
      "[Epoch   2]:  lr 0.000200 | train loss 0.12374 | val loss 0.11069 | val CER 0.38273 | val CER(torch) 0.38273\n",
      "[Epoch   3]:  lr 0.000200 | train loss 0.08105 | val loss 0.09075 | val CER 0.30545 | val CER(torch) 0.30545\n",
      "[Epoch   4]:  lr 0.000200 | train loss 0.07111 | val loss 0.07425 | val CER 0.24091 | val CER(torch) 0.24000\n",
      "[Epoch   5]:  lr 0.000200 | train loss 0.05741 | val loss 0.07411 | val CER 0.19682 | val CER(torch) 0.19682\n",
      "[Epoch   6]:  lr 0.000200 | train loss 0.05630 | val loss 0.08205 | val CER 0.22818 | val CER(torch) 0.22818\n",
      "[Epoch   7]:  lr 0.000200 | train loss 0.05775 | val loss 0.07594 | val CER 0.18909 | val CER(torch) 0.18909\n",
      "[Epoch   8]:  lr 0.000200 | train loss 0.04925 | val loss 0.07960 | val CER 0.17364 | val CER(torch) 0.17364\n",
      "[Epoch   9]:  lr 0.000200 | train loss 0.05447 | val loss 0.07403 | val CER 0.17773 | val CER(torch) 0.17773\n",
      "[Epoch  10]:  lr 0.000200 | train loss 0.05104 | val loss 0.05908 | val CER 0.14000 | val CER(torch) 0.14000\n",
      "[Epoch  11]:  lr 0.000200 | train loss 0.04800 | val loss 0.05451 | val CER 0.13091 | val CER(torch) 0.13091\n",
      "[Epoch  12]:  lr 0.000200 | train loss 0.04510 | val loss 0.05887 | val CER 0.13136 | val CER(torch) 0.13136\n",
      "[Epoch  13]:  lr 0.000200 | train loss 0.04444 | val loss 0.05779 | val CER 0.12682 | val CER(torch) 0.12682\n",
      "[Epoch  14]:  lr 0.000200 | train loss 0.04381 | val loss 0.05767 | val CER 0.12818 | val CER(torch) 0.12818\n",
      "[Epoch  15]:  lr 0.000200 | train loss 0.04841 | val loss 0.06089 | val CER 0.14136 | val CER(torch) 0.14136\n",
      "[Epoch  16]:  lr 0.000200 | train loss 0.04838 | val loss 0.06041 | val CER 0.13273 | val CER(torch) 0.13273\n",
      "[Epoch  17]:  lr 0.000200 | train loss 0.04853 | val loss 0.06391 | val CER 0.12955 | val CER(torch) 0.12955\n",
      "[Epoch  18]:  lr 0.000200 | train loss 0.04564 | val loss 0.05217 | val CER 0.08682 | val CER(torch) 0.08682\n",
      "[Epoch  19]:  lr 0.000200 | train loss 0.04138 | val loss 0.05368 | val CER 0.09864 | val CER(torch) 0.09864\n",
      "[Epoch  20]:  lr 0.000200 | train loss 0.04026 | val loss 0.04895 | val CER 0.07636 | val CER(torch) 0.07636\n",
      "[Epoch  21]:  lr 0.000200 | train loss 0.04196 | val loss 0.04923 | val CER 0.07273 | val CER(torch) 0.07273\n",
      "[Epoch  22]:  lr 0.000200 | train loss 0.04048 | val loss 0.04880 | val CER 0.07273 | val CER(torch) 0.07273\n",
      "[Epoch  23]:  lr 0.000200 | train loss 0.03948 | val loss 0.04832 | val CER 0.07364 | val CER(torch) 0.07364\n",
      "[Epoch  24]:  lr 0.000200 | train loss 0.03972 | val loss 0.05235 | val CER 0.07682 | val CER(torch) 0.07682\n",
      "[Epoch  25]:  lr 0.000200 | train loss 0.03955 | val loss 0.04806 | val CER 0.06273 | val CER(torch) 0.06273\n",
      "[Epoch  26]:  lr 0.000200 | train loss 0.03928 | val loss 0.04790 | val CER 0.05636 | val CER(torch) 0.05636\n",
      "[Epoch  27]:  lr 0.000200 | train loss 0.03938 | val loss 0.04779 | val CER 0.05364 | val CER(torch) 0.05364\n",
      "[Epoch  28]:  lr 0.000200 | train loss 0.03947 | val loss 0.04721 | val CER 0.05727 | val CER(torch) 0.05727\n",
      "[Epoch  29]:  lr 0.000200 | train loss 0.03914 | val loss 0.04722 | val CER 0.05364 | val CER(torch) 0.05364\n",
      "[Epoch  30]:  lr 0.000200 | train loss 0.03932 | val loss 0.04707 | val CER 0.05545 | val CER(torch) 0.05545\n",
      "[Epoch  31]:  lr 0.000200 | train loss 0.03918 | val loss 0.04721 | val CER 0.05000 | val CER(torch) 0.05000\n",
      "[Epoch  32]:  lr 0.000200 | train loss 0.03930 | val loss 0.04700 | val CER 0.05273 | val CER(torch) 0.05273\n",
      "[Epoch  33]:  lr 0.000200 | train loss 0.03907 | val loss 0.04695 | val CER 0.05000 | val CER(torch) 0.05000\n",
      "[Epoch  34]:  lr 0.000200 | train loss 0.03924 | val loss 0.04716 | val CER 0.05000 | val CER(torch) 0.05000\n",
      "[Epoch  35]:  lr 0.000200 | train loss 0.03918 | val loss 0.04717 | val CER 0.05091 | val CER(torch) 0.05091\n",
      "[Epoch  36]:  lr 0.000200 | train loss 0.03918 | val loss 0.04746 | val CER 0.05091 | val CER(torch) 0.05091\n",
      "[Epoch  37]:  lr 0.000200 | train loss 0.03937 | val loss 0.04752 | val CER 0.04909 | val CER(torch) 0.04909\n",
      "[Epoch  38]:  lr 0.000200 | train loss 0.03906 | val loss 0.04723 | val CER 0.04455 | val CER(torch) 0.04455\n",
      "[Epoch  39]:  lr 0.000200 | train loss 0.03931 | val loss 0.04734 | val CER 0.04636 | val CER(torch) 0.04636\n",
      "[Epoch  40]:  lr 0.000200 | train loss 0.03917 | val loss 0.04749 | val CER 0.04818 | val CER(torch) 0.04818\n",
      "Epoch 00041: reducing learning rate of group 0 to 1.0000e-04.\n",
      "[Epoch  41]:  lr 0.000100 | train loss 0.03930 | val loss 0.04721 | val CER 0.04818 | val CER(torch) 0.04818\n",
      "[Epoch  42]:  lr 0.000100 | train loss 0.03934 | val loss 0.04732 | val CER 0.04727 | val CER(torch) 0.04727\n",
      "[Epoch  43]:  lr 0.000100 | train loss 0.03922 | val loss 0.04714 | val CER 0.04455 | val CER(torch) 0.04455\n",
      "[Epoch  44]:  lr 0.000100 | train loss 0.03917 | val loss 0.04712 | val CER 0.04545 | val CER(torch) 0.04545\n",
      "[Epoch  45]:  lr 0.000100 | train loss 0.03917 | val loss 0.04734 | val CER 0.04636 | val CER(torch) 0.04636\n",
      "[Epoch  46]:  lr 0.000100 | train loss 0.03922 | val loss 0.04711 | val CER 0.04727 | val CER(torch) 0.04727\n",
      "[Epoch  47]:  lr 0.000100 | train loss 0.03922 | val loss 0.04757 | val CER 0.04545 | val CER(torch) 0.04545\n",
      "[Epoch  48]:  lr 0.000100 | train loss 0.03917 | val loss 0.04725 | val CER 0.04545 | val CER(torch) 0.04545\n",
      "Epoch 00049: reducing learning rate of group 0 to 5.0000e-05.\n",
      "[Epoch  49]:  lr 0.000050 | train loss 0.03922 | val loss 0.04749 | val CER 0.04818 | val CER(torch) 0.04818\n",
      "[Epoch  50]:  lr 0.000050 | train loss 0.03917 | val loss 0.04704 | val CER 0.04545 | val CER(torch) 0.04545\n",
      "[Epoch  51]:  lr 0.000050 | train loss 0.03922 | val loss 0.04700 | val CER 0.04273 | val CER(torch) 0.04273\n",
      "[Epoch  52]:  lr 0.000050 | train loss 0.03922 | val loss 0.04735 | val CER 0.04455 | val CER(torch) 0.04455\n",
      "[Epoch  53]:  lr 0.000050 | train loss 0.03928 | val loss 0.04705 | val CER 0.04455 | val CER(torch) 0.04455\n",
      "[Epoch  54]:  lr 0.000050 | train loss 0.03911 | val loss 0.04725 | val CER 0.04455 | val CER(torch) 0.04455\n",
      "[Epoch  55]:  lr 0.000050 | train loss 0.03916 | val loss 0.04717 | val CER 0.04545 | val CER(torch) 0.04545\n",
      "[Epoch  56]:  lr 0.000050 | train loss 0.03928 | val loss 0.04708 | val CER 0.04455 | val CER(torch) 0.04455\n",
      "Epoch 00057: reducing learning rate of group 0 to 2.5000e-05.\n",
      "[Epoch  57]:  lr 0.000025 | train loss 0.03933 | val loss 0.04751 | val CER 0.04636 | val CER(torch) 0.04636\n",
      "[Epoch  58]:  lr 0.000025 | train loss 0.03939 | val loss 0.04714 | val CER 0.04545 | val CER(torch) 0.04545\n",
      "[Epoch  59]:  lr 0.000025 | train loss 0.03911 | val loss 0.04697 | val CER 0.04545 | val CER(torch) 0.04545\n",
      "[Epoch  60]:  lr 0.000025 | train loss 0.03933 | val loss 0.04714 | val CER 0.04364 | val CER(torch) 0.04364\n",
      "[Epoch  61]:  lr 0.000025 | train loss 0.03928 | val loss 0.04721 | val CER 0.04545 | val CER(torch) 0.04545\n",
      "[Epoch  62]:  lr 0.000025 | train loss 0.03911 | val loss 0.04739 | val CER 0.04364 | val CER(torch) 0.04364\n",
      "[Epoch  63]:  lr 0.000025 | train loss 0.03916 | val loss 0.04732 | val CER 0.04273 | val CER(torch) 0.04273\n",
      "[Epoch  64]:  lr 0.000025 | train loss 0.03928 | val loss 0.04733 | val CER 0.04455 | val CER(torch) 0.04455\n",
      "Epoch 00065: reducing learning rate of group 0 to 1.2500e-05.\n",
      "[Epoch  65]:  lr 0.000012 | train loss 0.03939 | val loss 0.04716 | val CER 0.04273 | val CER(torch) 0.04273\n",
      "[Epoch  66]:  lr 0.000012 | train loss 0.03916 | val loss 0.04750 | val CER 0.04000 | val CER(torch) 0.04000\n",
      "[Epoch  67]:  lr 0.000012 | train loss 0.03933 | val loss 0.04742 | val CER 0.04182 | val CER(torch) 0.04182\n",
      "[Epoch  68]:  lr 0.000012 | train loss 0.03916 | val loss 0.04762 | val CER 0.04273 | val CER(torch) 0.04273\n",
      "[Epoch  69]:  lr 0.000012 | train loss 0.03928 | val loss 0.04751 | val CER 0.04545 | val CER(torch) 0.04545\n",
      "[Epoch  70]:  lr 0.000012 | train loss 0.03911 | val loss 0.04748 | val CER 0.04818 | val CER(torch) 0.04818\n",
      "[Epoch  71]:  lr 0.000012 | train loss 0.03911 | val loss 0.04724 | val CER 0.04455 | val CER(torch) 0.04455\n",
      "[Epoch  72]:  lr 0.000012 | train loss 0.03928 | val loss 0.04763 | val CER 0.04182 | val CER(torch) 0.04182\n",
      "Epoch 00073: reducing learning rate of group 0 to 6.2500e-06.\n",
      "[Epoch  73]:  lr 0.000006 | train loss 0.03916 | val loss 0.04710 | val CER 0.04182 | val CER(torch) 0.04182\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch  74]:  lr 0.000006 | train loss 0.03922 | val loss 0.04733 | val CER 0.04545 | val CER(torch) 0.04545\n",
      "[Epoch  75]:  lr 0.000006 | train loss 0.03922 | val loss 0.04720 | val CER 0.04273 | val CER(torch) 0.04273\n",
      "[Epoch  76]:  lr 0.000006 | train loss 0.03916 | val loss 0.04769 | val CER 0.04364 | val CER(torch) 0.04364\n",
      "[Epoch  77]:  lr 0.000006 | train loss 0.03962 | val loss 0.04760 | val CER 0.04364 | val CER(torch) 0.04364\n",
      "[Epoch  78]:  lr 0.000006 | train loss 0.03952 | val loss 0.04745 | val CER 0.04455 | val CER(torch) 0.04455\n",
      "[Epoch  79]:  lr 0.000006 | train loss 0.03922 | val loss 0.04746 | val CER 0.04091 | val CER(torch) 0.04091\n",
      "[Epoch  80]:  lr 0.000006 | train loss 0.03933 | val loss 0.04741 | val CER 0.04364 | val CER(torch) 0.04364\n",
      "Epoch 00081: reducing learning rate of group 0 to 3.1250e-06.\n",
      "[Epoch  81]:  lr 0.000003 | train loss 0.03916 | val loss 0.04732 | val CER 0.04364 | val CER(torch) 0.04364\n",
      "[Epoch  82]:  lr 0.000003 | train loss 0.03916 | val loss 0.04742 | val CER 0.04364 | val CER(torch) 0.04364\n",
      "[Epoch  83]:  lr 0.000003 | train loss 0.03916 | val loss 0.04735 | val CER 0.04545 | val CER(torch) 0.04545\n",
      "[Epoch  84]:  lr 0.000003 | train loss 0.03911 | val loss 0.04720 | val CER 0.04273 | val CER(torch) 0.04273\n",
      "[Epoch  85]:  lr 0.000003 | train loss 0.03922 | val loss 0.04751 | val CER 0.04000 | val CER(torch) 0.04000\n",
      "[Epoch  86]:  lr 0.000003 | train loss 0.03922 | val loss 0.04744 | val CER 0.04545 | val CER(torch) 0.04545\n",
      "[Epoch  87]:  lr 0.000003 | train loss 0.03939 | val loss 0.04741 | val CER 0.04455 | val CER(torch) 0.04455\n",
      "[Epoch  88]:  lr 0.000003 | train loss 0.03922 | val loss 0.04742 | val CER 0.04273 | val CER(torch) 0.04273\n",
      "Epoch 00089: reducing learning rate of group 0 to 1.5625e-06.\n",
      "[Epoch  89]:  lr 0.000002 | train loss 0.03916 | val loss 0.04720 | val CER 0.04455 | val CER(torch) 0.04455\n",
      "[Epoch  90]:  lr 0.000002 | train loss 0.03916 | val loss 0.04711 | val CER 0.04455 | val CER(torch) 0.04455\n",
      "[Epoch  91]:  lr 0.000002 | train loss 0.03930 | val loss 0.04702 | val CER 0.04273 | val CER(torch) 0.04273\n",
      "[Epoch  92]:  lr 0.000002 | train loss 0.03911 | val loss 0.04748 | val CER 0.04182 | val CER(torch) 0.04182\n",
      "[Epoch  93]:  lr 0.000002 | train loss 0.03922 | val loss 0.04738 | val CER 0.04636 | val CER(torch) 0.04636\n",
      "[Epoch  94]:  lr 0.000002 | train loss 0.03922 | val loss 0.04732 | val CER 0.04182 | val CER(torch) 0.04182\n",
      "[Epoch  95]:  lr 0.000002 | train loss 0.03935 | val loss 0.04734 | val CER 0.04273 | val CER(torch) 0.04273\n",
      "[Epoch  96]:  lr 0.000002 | train loss 0.03941 | val loss 0.04756 | val CER 0.04000 | val CER(torch) 0.04000\n",
      "Epoch 00097: reducing learning rate of group 0 to 7.8125e-07.\n",
      "[Epoch  97]:  lr 0.000001 | train loss 0.03922 | val loss 0.04737 | val CER 0.04273 | val CER(torch) 0.04273\n",
      "[Epoch  98]:  lr 0.000001 | train loss 0.03916 | val loss 0.04778 | val CER 0.04273 | val CER(torch) 0.04273\n",
      "[Epoch  99]:  lr 0.000001 | train loss 0.03911 | val loss 0.04732 | val CER 0.04273 | val CER(torch) 0.04273\n",
      "[Epoch 100]:  lr 0.000001 | train loss 0.03911 | val loss 0.04762 | val CER 0.04545 | val CER(torch) 0.04545\n",
      "CPU times: user 7min 38s, sys: 46.6 s, total: 8min 25s\n",
      "Wall time: 8min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for epoch in range(1, 101):\n",
    "    train_loss, test_loss = train(model)\n",
    "    loss_curve_train.append(train_loss)\n",
    "    loss_curve_test.append(test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmcAAAHwCAYAAADjOch3AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAABIqklEQVR4nO3deZhcZZ33/8/31NZ7d5LOvkCAAEGEBMImCDI4Cqig46iAOD6ODDIz7ssI+htneR5/wyzPjDojICruCAoyoqyiKDCAkkDYl4RASGffOum9tvv54z7V3Wk6oav6nK7q5P26rr6q69Q5de6qU8unvuc+5zbnnAAAAFAbgmo3AAAAAEMIZwAAADWEcAYAAFBDCGcAAAA1hHAGAABQQwhnAAAANYRwBmC/ZGZ3mNkHo563zDa8ycw6or5fAPu3ZLUbAAAlZtY97GqDpAFJhfD6R5xzPxrrfTnnzoljXgCIG+EMQM1wzjWV/jezlyVd4py7Z+R8ZpZ0zuUnsm0AMFHYrQmg5pV2D5rZ581sk6TvmNkUM/ulmW01s53h//OGLfNbM7sk/P9/mdkDZvZv4bwvmdk5Fc670MzuM7MuM7vHzL5uZj8c4+NYHK6r08yeNrPzht12rpk9E97vejP7bDi9PXxsnWa2w8zuNzM+u4H9GG9wAJPFLElTJR0k6VL5z6/vhNcXSOqT9F/7WP4kSc9Lapf0L5K+bWZWwbzXS/qDpGmS/l7SB8bSeDNLSfqFpLslzZD0MUk/MrMjwlm+Lb/rtlnS0ZJ+E07/jKQOSdMlzZT0BUmMuwfsxwhnACaLoqS/c84NOOf6nHPbnXM3O+d6nXNdkr4s6Yx9LL/WOfdN51xB0vckzZYPO2Oe18wWSDpB0pecc1nn3AOSbh1j+0+W1CTpynDZ30j6paQLw9tzko4ysxbn3E7n3KPDps+WdJBzLuecu98xKDKwXyOcAZgstjrn+ktXzKzBzL5hZmvNbLek+yS1mVliL8tvKv3jnOsN/20qc945knYMmyZJ68bY/jmS1jnnisOmrZU0N/z/3ZLOlbTWzH5nZqeE0/9V0mpJd5vZGjO7fIzrAzBJEc4ATBYjq0WfkXSEpJOccy2STg+n721XZRQ2SppqZg3Dps0f47IbJM0f0V9sgaT1kuSce8Q5d778Ls//lvSTcHqXc+4zzrlDJL1D0qfN7KzxPQwAtYxwBmCyapbvZ9ZpZlMl/V3cK3TOrZW0XNLfm1k6rG69Y4yL/15Sj6S/MbOUmb0pXPaG8L7eb2atzrmcpN0KTyFiZm83s8PCPm+l6YVR1wBgv0A4AzBZfUVSvaRtkh6WdOcErff9kk6RtF3S/5F0o/z52PbJOZeVdJ6kc+TbfJWkP3POPRfO8gFJL4e7aC+TdHE4fZGkeyR1S3pI0lXOud9G9WAA1B6jXykAVM7MbpT0nHMu9sodgAMDlTMAKIOZnWBmh5pZYGZnSzpfvo8YAESCEQIAoDyzJP1M/jxnHZL+0jn3WHWbBGB/wm5NAACAGsJuTQAAgBpCOAMAAKgh+1Wfs/b2dnfwwQdXuxkAAACvacWKFducc9NHTt+vwtnBBx+s5cuXV7sZAAAAr8nM1o42nd2aAAAANYRwBgAAUEMIZwAAADVkv+pzBgAAJodcLqeOjg719/dXuymxq6ur07x585RKpcY0P+EMAABMuI6ODjU3N+vggw+WmVW7ObFxzmn79u3q6OjQwoULx7QMuzUBAMCE6+/v17Rp0/brYCZJZqZp06aVVSEknAEAgKrY34NZSbmPk3AGAAAOOJ2dnbrqqqvKXu7cc89VZ2dn9A0ahnAGAAAOOHsLZ4VCYZ/L3X777Wpra4upVR4HBAAAgAPO5ZdfrhdffFFLlixRKpVSU1OTZs+erZUrV+qZZ57RO9/5Tq1bt079/f36xCc+oUsvvVTS0GhE3d3dOuecc3TaaafpwQcf1Ny5c/Xzn/9c9fX1424b4QwAAFTVP/ziaT2zYXek93nUnBb93Ttet9fbr7zySj311FNauXKlfvvb3+ptb3ubnnrqqcEjKq+77jpNnTpVfX19OuGEE/Tud79b06ZN2+M+Vq1apR//+Mf65je/qfe+9726+eabdfHFF4+77YQzAABwwDvxxBP3ONXF1772Nd1yyy2SpHXr1mnVqlWvCmcLFy7UkiVLJEnHH3+8Xn755UjaQjgDAABVta8K10RpbGwc/P+3v/2t7rnnHj300ENqaGjQm970plFPhZHJZAb/TyQS6uvri6QtHBAAAAAOOM3Nzerq6hr1tl27dmnKlClqaGjQc889p4cffnhC20blDAAAHHCmTZumU089VUcffbTq6+s1c+bMwdvOPvtsXXPNNTrmmGN0xBFH6OSTT57QtplzbkJXGKdly5a55cuXV7sZAADgNTz77LNavHhxtZsxYUZ7vGa2wjm3bOS87NYsQ/dAXt0D+Wo3AwAA7McIZ2X406sf1KdvXFntZgAAgP0Y4awMyYQpX9x/dgMDAIDaQzgrQyoRKFcoVrsZAABgP0Y4K0MqIJwBAIB4Ec7KkEyY8gV2awIAgPgQzsqQTATK0ecMAIBJr7OzU1dddVVFy37lK19Rb29vxC0aQjgrQzphyrNbEwCASa+WwxkjBJQhSZ8zAAD2C5dffrlefPFFLVmyRH/8x3+sGTNm6Cc/+YkGBgb0rne9S//wD/+gnp4evfe971VHR4cKhYL+9m//Vps3b9aGDRt05plnqr29Xffee2/kbSOclYE+ZwAAxOCOy6VNT0Z7n7NeL51z5V5vvvLKK/XUU09p5cqVuvvuu3XTTTfpD3/4g5xzOu+883Tfffdp69atmjNnjm677TZJfszN1tZW/fu//7vuvfdetbe3R9vmELs1y5BKBMoVqZwBALA/ufvuu3X33Xdr6dKlOu644/Tcc89p1apVev3rX6977rlHn//853X//fertbV1QtpD5awMqYQpl6dyBgBApPZR4ZoIzjldccUV+shHPvKq21asWKHbb79dV1xxhd7ylrfoS1/6UuztoXJWhmQiUJ7KGQAAk15zc7O6urokSW9961t13XXXqbu7W5K0fv16bdmyRRs2bFBDQ4Muvvhiffazn9Wjjz76qmXjQOWsDKnAlKPPGQAAk960adN06qmn6uijj9Y555yjiy66SKeccookqampST/84Q+1evVqfe5zn1MQBEqlUrr66qslSZdeeqnOOecczZ49O5YDAsy5/SdsLFu2zC1fvjy2+//fv3xGN/zhFT39j2fHtg4AAA4Ezz77rBYvXlztZkyY0R6vma1wzi0bOS+7Ncvgx9bcf8IsAACoPYSzMqQSxtGaAAAgVoSzMiSDQM5JBYZwAgAAMSGclSGZMElilAAAACKwP/V735dyHyfhrAzphH+6CGcAAIxPXV2dtm/fvt8HNOectm/frrq6ujEvw6k0ylCqnDGEEwAA4zNv3jx1dHRo69at1W5K7Orq6jRv3rwxz084K0OyVDnjoAAAAMYllUpp4cKF1W5GTWK3ZhlSAZUzAAAQL8JZGVL0OQMAADEjnJVh6GhNKmcAACAehLMylCpnDH4OAADiQjgrw2A4o3IGAABiQjgrQ2m3ZpY+ZwAAICaEszKkAipnAAAgXoSzMgydhJbKGQAAiEes4czMzjaz581stZldPsrt7zezJ8K/B83s2GG3vWxmT5rZSjNbHmc7x2rwVBoMfA4AAGIS2wgBZpaQ9HVJfyypQ9IjZnarc+6ZYbO9JOkM59xOMztH0rWSThp2+5nOuW1xtbFcqdKpNPJUzgAAQDzirJydKGm1c26Ncy4r6QZJ5w+fwTn3oHNuZ3j1YUljH3iqCpIBp9IAAADxijOczZW0btj1jnDa3nxY0h3DrjtJd5vZCjO7NIb2lS3FSWgBAEDM4hz43EaZNmqqMbMz5cPZacMmn+qc22BmMyT9ysyec87dN8qyl0q6VJIWLFgw/lbvA8M3AQCAuMVZOeuQNH/Y9XmSNoycycyOkfQtSec757aXpjvnNoSXWyTdIr+b9FWcc9c655Y555ZNnz49wua/2tDRmlTOAABAPOIMZ49IWmRmC80sLekCSbcOn8HMFkj6maQPOOdeGDa90cyaS/9Leoukp2Js65gMHa1J5QwAAMQjtt2azrm8mX1U0l2SEpKuc849bWaXhbdfI+lLkqZJusrMJCnvnFsmaaakW8JpSUnXO+fujKutY5UMqJwBAIB4xdnnTM652yXdPmLaNcP+v0TSJaMst0bSsSOnV1sqSZ8zAAAQL0YIKENp+CaO1gQAAHEhnJWB4ZsAAEDcCGdlKPU5Y/gmAAAQF8JZGcxMqYTR5wwAAMSGcFamZBCwWxMAAMSGcFamZMI4IAAAAMSGcFamVCJg4HMAABAbwlmZUglTLk/lDAAAxINwVqZkEDB8EwAAiA3hrEyphDF8EwAAiA3hrExJ+pwBAIAYEc7KlEoEytLnDAAAxIRwVqZUwqicAQCA2BDOypQM6HMGAADiQzgrUyoRMHwTAACIDeGsTIQzAAAQJ8JZmZIJU77Ibk0AABAPwlmZkkHA2JoAACA2hLMypZPGbk0AABAbwlmZkkGgPOEMAADEhHBWpmTC2K0JAABiQzgrUypg+CYAABAfwlmZUkkqZwAAID6EszL5ozWpnAEAgHgQzsqUSjB8EwAAiA/hrEzJBH3OAABAfAhnZfLDNzk5R/UMAABEj3BWplRgksQQTgAAIBaEszIlE/4po98ZAACIA+GsTKmEr5zl6HcGAABiQDgrUyqsnOXyhDMAABA9wlmZkgn6nAEAgPgQzsqUCsLKGSeiBQAAMSCclWmwcsYBAQAAIAaEszIN9jmjcgYAAGJAOCvT4NGaVM4AAEAMCGdlSoZ9zhjCCQAAxIFwVqZUsrRbk8oZAACIHuGsTKXhm+hzBgAA4kA4KxPDNwEAgDgRzsqUZPgmAAAQI8JZmdIM3wQAAGJEOCsTwzcBAIA4Ec7KlGT4JgAAECPCWZlSDN8EAABiRDgrE8M3AQCAOBHOyjR0tCaVMwAAED3CWZlSpeGbqJwBAIAYEM7KlKTPGQAAiBHhrEylPmdZKmcAACAGhLMypRi+CQAAxIhwVqZEYDKT8gzfBAAAYkA4q0AqCJSjcgYAAGJAOKtAKmGc5wwAAMSCcFaBZCLgVBoAACAWhLMKpBLGSWgBAEAsCGcVSAZUzgAAQDwIZxVIJY0DAgAAQCwIZxXwR2tSOQMAANEjnFUgmTBOQgsAAGJBOKtAKhFwEloAABALwlkFkolAWSpnAAAgBoSzCqQC42hNAAAQC8JZBehzBgAA4kI4q0AqEShL5QwAAMSAcFYBDggAAABxIZxVIBmwWxMAAMSDcFaBVIKT0AIAgHgQziqQSjB8EwAAiAfhrALJBAOfAwCAeBDOKpBKmHJFKmcAACB6hLMKJAMqZwAAIB6Eswr4AwKonAEAgOgRzirgDwigcgYAAKJHOKtAMmHK0+cMAADEgHBWgWQQqFB0KhLQAABAxAhnFUgn/dOWYwgnAAAQsVjDmZmdbWbPm9lqM7t8lNvfb2ZPhH8PmtmxY122mpKBSRJDOAEAgMjFFs7MLCHp65LOkXSUpAvN7KgRs70k6Qzn3DGS/reka8tYtmqSCf+0Ec4AAEDU4qycnShptXNujXMuK+kGSecPn8E596Bzbmd49WFJ88a6bDWlEr5yxm5NAAAQtTjD2VxJ64Zd7win7c2HJd1R4bITKhVWzjidBgAAiFoyxvu2UaaNuh/QzM6UD2enVbDspZIulaQFCxaU38oK0OcMAADEJc7KWYek+cOuz5O0YeRMZnaMpG9JOt85t72cZSXJOXetc26Zc27Z9OnTI2n4a6FyBgAA4hJnOHtE0iIzW2hmaUkXSLp1+AxmtkDSzyR9wDn3QjnLVlMy7HPGiWgBAEDUYtut6ZzLm9lHJd0lKSHpOufc02Z2WXj7NZK+JGmapKvMTJLyYRVs1GXjamu5SpWzbJ7KGQAAiFacfc7knLtd0u0jpl0z7P9LJF0y1mVrRYrKGQAAiAkjBFQgGZTOc0blDAAARItwVoHB3ZqEMwAAEDHCWQUGd2tyKg0AABAxwlkFBodvYoQAAAAQMcJZBUonoc1ROQMAABEjnFUgneQktAAAIB6EswowfBMAAIgL4awCDN8EAADiQjirAMM3AQCAuBDOKkDlDAAAxIVwVoFUUApnVM4AAEC0CGcVGNytSeUMAABEjHBWAfqcAQCAuBDOKlDarZnNUzkDAADRIpxVIAhMicAYvgkAAESOcFahZGCchBYAAESOcFahVCLgaE0AABA5wlmFUgnjPGcAACByhLMKJRMBfc4AAEDkCGcVSgXGbk0AABA5wlmFkomAk9ACAIDIEc4q5PucUTkDAADRIpxVyB+tSeUMAABEi3BWoWTCGL4JAABEjnBWISpnAAAgDoSzCqUCwhkAAIge4axCyQTDNwEAgOgRziqUTATK0ecMAABEjHBWoXTClMuzWxMAAESLcFahZMDwTQAAIHqEswrR5wwAAMSBcFahVCJQjsoZAACIGOGsQqmEKZencgYAAKJFOKtQMkGfMwAAED3CWYVSAQOfAwCA6BHOKpRMBMozQgAAAIgY4axCfmxNKmcAACBahLMKpRLG0ZoAACByhLMKJYNAzkkFhnACAAARIpxVKJkwSVKOfmcAACBChLMKpRP+qSOcAQCAKBHOKlSqnDGEEwAAiBLhrELJUuWMgwIAAECECGcVSgVUzgAAQPQIZxVK0ecMAADEgHBWjufvkNb8TtLwozWpnAEAgOgkq92ASeXeL0st86RDzhisnDH4OQAAiBKVs3Kkm6VstyQpGfY5y+WpnAEAgOgQzsqRbhwMZ6kkR2sCAIDoEc7KkWmSBsJwFoS7NelzBgAAIkQ4K0e6aWi35uBJaKmcAQCA6BDOypFpHqqchQcEZAlnAAAgQoSzcpQqZ84pxfBNAAAgBoSzcmSaJDkp16tkwKk0AABA9Ahn5Ug3+suB7sHKGSehBQAAUSKclSPd7C+z3QzfBAAAYkE4K0emyV8OdA07WpPKGQAAiA7hrBzpMJwNr5zR5wwAAESIcFaOwcpZ9+DwTVTOAABAlAhn5Rje5yxJnzMAABA9wlk5SkdrZrsHh2/iaE0AABAlwlk5hu/WZPgmAAAQA8JZOYYdEFDqc5YrUjkDAADRIZyVI0hIqQZpoEtmplTC6HMGAAAiRTgrV2l8TUnJIGC3JgAAiBThrFyZJinbI0lKJowDAgAAQKQIZ+VKN0oDvnKWSgQMfA4AACI1pnBmZp8wsxbzvm1mj5rZW+JuXE1KNw/u1kwlTLk8lTMAABCdsVbO/tw5t1vSWyRNl/QhSVfG1qpalmmSBrok+T5nDN8EAACiNNZwZuHluZK+45x7fNi0A8uwAwJSCWP4JgAAEKmxhrMVZna3fDi7y8yaJR2YJaNM02Cfs2Qi4FQaAAAgUskxzvdhSUskrXHO9ZrZVPldmweedPPg0ZqpRMDRmgAAIFJjrZydIul551ynmV0s6f+TtCu+ZtWwdKPfremc361JnzMAABChsYazqyX1mtmxkv5G0lpJ34+tVbUs0yTJSdkeJQP6nAEAgGiNNZzlnXNO0vmSvuqc+6qk5viaVcOGja+ZSgTK0ucMAABEaKx9zrrM7ApJH5D0RjNLSErF16walgkz6YAPZ73ZfHXbAwAA9itjrZy9T9KA/PnONkmaK+lfY2tVLRusnHUpmTDli+zWBAAA0RlTOAsD2Y8ktZrZ2yX1O+des8+ZmZ1tZs+b2Wozu3yU2480s4fMbMDMPjvitpfN7EkzW2lmy8f4eOKXbvSX2R5/Elr6nAEAgAiNdfim90r6g6T3SHqvpN+b2Z++xjIJSV+XdI6koyRdaGZHjZhth6SPS/q3vdzNmc65Jc65ZWNp54TIhJWzgW6lk8Z5zgAAQKTG2ufsi5JOcM5tkSQzmy7pHkk37WOZEyWtds6tCZe5Qf6AgmdKM4T3t8XM3lZB26sjHfY5y3YrGcxUnnAGAAAiNNY+Z0EpmIW2j2HZuZLWDbveEU4bKyfpbjNbYWaXlrFcvAYrZ77PGbs1AQBAlMZaObvTzO6S9OPw+vsk3f4ay4w29mY5SeZU59wGM5sh6Vdm9pxz7r5XrcQHt0slacGCBWXcfYWGn0ojCDgJLQAAiNRYDwj4nKRrJR0j6VhJ1zrnPv8ai3VImj/s+jxJG8baMOfchvByi6Rb5HeTjjbftc65Zc65ZdOnTx/r3VeudEDAQLdSSSpnAAAgWmOtnMk5d7Okm8u470ckLTKzhZLWS7pA0kVjWdDMGuV3pXaF/79F0j+Wse74BAkp1RD2OWPgcwAAEK19hjMz69LouyJNknPOtextWedc3sw+KukuSQlJ1znnnjazy8LbrzGzWZKWS2qRVDSzT8of2dku6RYzK7XxeufcneU+uNikm8IRAhi+CQAARGuf4cw5N64hmpxzt2tE3zTn3DXD/t8kv7tzpN3yu09rU6ZJGuhWsok+ZwAAIFpjPVoTww1WzvxJaP2wowAAAONHOKtEptkfEBD4A1IZwgkAAESFcFaJdFM4tqZ/+uh3BgAAokI4q0S6Ucr2KJXwlbMc/c4AAEBECGeVCA8ISIWVs1yecAYAAKJBOKtEutmf5yxBnzMAABAtwlklMuHRmuEAVZyIFgAARIVwVolwfM069UsSQzgBAIDIEM4qkQnDWbFPkpSncgYAACJCOKtEqXLmeiVROQMAANEhnFUiDGeZQlg541QaAAAgIoSzSoS7NTPFUuWMcAYAAKJBOKtEemQ4Y7cmAACIBuGsEplmSVK64MMZwzcBAICoEM4qEVbOUoUeSQzfBAAAokM4q0S6UZKUCg8IYPgmAAAQFcJZJUqVs7yvnDF8EwAAiArhrBJBIKUalQjDGUdrAgCAqBDOKpVpUrJUOeOAAAAAEBHCWaXSTUrkqJwBAIBoEc4qlWlSIt8tScrR5wwAAESEcFapdJOCXOk8Z1TOAABANAhnlUo3Kcj6yhl9zgAAQFQIZ5XKNMnCPmdZKmcAACAihLNKpZtkVM4AAEDECGeVyjTLBrplJuUZvgkAAESEcFapdJOU61E6kHJUzgAAQEQIZ5UKx9dsSWQ5zxkAAIgM4axSGT++ZmswwKk0AABAZAhnlUo3S5JaE/2chBYAAESGcFapsHLWbAPK5amcAQCAaBDOKpX24awl0a88lTMAABARwlmlSgcEWD8HBAAAgMgQziqV8X3OGm2Ak9ACAIDIEM4qFe7WbKJyBgAAIkQ4q1RmWDijzxkAAIgI4axSKd/nrFF9nOcMAABEhnBWqSCQ0k1hOKNyBgAAokE4G490oxrUryyVMwAAEBHC2Xikm9SgfuWLhDMAABANwtl4ZJrU4PrUmy1UuyUAAGA/QTgbj3Szmqxfu/ty1W4JAADYTxDOxiOsnHX25uQcBwUAAIDxI5yNR7pJda5X+aJTD7s2AQBABAhn45FuVLrYK0nq7M1WuTEAAGB/QDgbj0yzUvk+SdIu+p0BAIAIEM7GI92kZKFXpqJ29RLOAADA+BHOxiMcX7NR/eqkcgYAACJAOBuP9LBwRuUMAABEgHA2HplmSVKT9amzjwMCAADA+BHOxiPdKElqS2TpcwYAACJBOBuPcLfmjEyOozUBAEAkCGfjER4QMD2To88ZAACIBOFsPNK+z1l7KkefMwAAEAnC2XiElbOpqSyVMwAAEAnC2XiEfc7aEgP0OQMAAJEgnI1HqkGS1BpwnjMAABANwtl4BIGUblJzMKC+XEED+UK1WwQAACY5wtl4pZvUaP2SGPwcAACMH+FsvDJNanB9ksSJaAEAwLgRzsYr3aS6MJwx+DkAABgvwtl4ZZqVKfZKEgcFAACAcSOcjVemWelclySps5cT0QIAgPEhnI1X20FK7X5FkuOAAAAAMG6Es/Gadqgs16NZ1kk4AwAA40Y4G69ph0mSjq7bSp8zAAAwboSz8QrD2eLUZo7WBAAA40Y4G6+WuVKyXocmNnFAAAAAGDfC2XgFgTTtUB3kNtLnDAAAjBvhLArTDtWc4nrCGQAAGDfCWRSmHab27AZ19/RVuyUAAGCSI5xFYdphSqigluwGFYqu2q0BAACTGOEsCuERmwu1UV397NoEAACVI5xFoRTObCPnOgMAAONCOItCw1Rl0206xDZxrjMAADAuhLOIZFsP0ULjdBoAAGB8CGcRKU49VAsDTkQLAADGJ9ZwZmZnm9nzZrbazC4f5fYjzewhMxsws8+Ws2ytSUxfpNm2Qz1du6rdFAAAMInFFs7MLCHp65LOkXSUpAvN7KgRs+2Q9HFJ/1bBsjUlM/NwSZLteLHKLQEAAJNZnJWzEyWtds6tcc5lJd0g6fzhMzjntjjnHpE0sqPWay5ba5LTF0mSUp0vVbklAABgMosznM2VtG7Y9Y5wWtzLVse0QyVJjd2EMwAAULk4w5mNMm2sp88f87JmdqmZLTez5Vu3bh1z4yKXqteWYLrael+pXhsAAMCkF2c465A0f9j1eZI2RL2sc+5a59wy59yy6dOnV9TQqGxOzVP7wLrXnhEAAGAv4gxnj0haZGYLzSwt6QJJt07AslWzo26BZuc7JMf4mgAAoDLJuO7YOZc3s49KuktSQtJ1zrmnzeyy8PZrzGyWpOWSWiQVzeyTko5yzu0ebdm42hqV3Y0HqWlXj9SzTWqqbhUPAABMTrGFM0lyzt0u6fYR064Z9v8m+V2WY1q21vU1L5Qkue2rZIQzAABQAUYIiFBuij9iM7t5VZVbAgAAJivCWYSSUxYo6xLKbnmh2k0BAACTFOEsQq2NdVrrZsltW13tpgAAgEmKcBah1vq0XnKzlNzJEE4AAKAyhLMItdantMbNVl3Xy1KxUO3mAACASYhwFqG2hpRecrMVFHPSLk5GCwAAykc4i1BbQ0prirP9le30OwMAAOUjnEWoPpVQRzDHX9lOvzMAAFA+wlmEzEz5+nb1B43SNs51BgAAykc4i1hbQ1qbUvPYrQkAACpCOItYa33K79oknAEAgAoQziLW1pDSi26eP1pzoKvazQEAAJMM4SxirfVpPV2Y769sfqa6jQEAAJMO4SxibQ0pPToQHrG5+anqNgYAAEw6hLOItdWntDo7RS7TIm1+utrNAQAAkwzhLGKtDSlJplz7UYQzAABQNsJZxFrrU5Kk3ilH+HDmXJVbBAAAJhPCWcTaGtKSpM7mw6Vsl9T5SpVbBAAAJhPCWcTawsrZ1oZFfgK7NgEAQBkIZxFra/DhbH36YD+BcAYAAMpAOItYW73frbk9l5amLJQ2P1nlFgEAgMmEcBax5rqkzKRdvVlp1tFUzgAAQFkIZxELAlNLXUqdfTlp5tHS9helbG+1mwUAACYJwlkM2hpS6uzNSTNfJ8lJW5+tdpMAAMAkQTiLQVt9Srv6SuFM7NoEAABjRjiLQWtD2u/WbDtYSjWWF856tks/eq+0bVVs7QMAALWLcBaDtvqUPyAgCKSZZQ7jtPJH0qq7pN/8n/gaCAAAahbhLAZTGlLa1p1Vsej8QQGbnhzbME7OSSuvl2TSMz+Xtj4fe1sBAEBtIZzF4LiDpqh7IK+VHZ2+31l/p7R7w2svuOExf/DAmV+UUvXS/f837qYCAIAaQziLwRmHT1ciMP3m2S2+ciaNbdfmyuulREY68S+kZX8uPflTfyqO0TgnrfietIUjQQEA2J8QzmLQ1pDW8QdN0T3PbvZ9ziRp81P7Xig/4MPY4rdL9W3SGz4mBSnpgf8Yff7ff0P6xcelm/5cKhYibT8AAKgewllM3rx4hp7b1KX1/WmpdcFrV85euNPv/lxykb/ePEs6/oPS4z+WOl/Zc941v5Xu+oI07TBpyzM+1AEAgP0C4Swmf3TkTEnSb57d7PudvVY4W3m91DxbOuTMoWmnfkKSSQ98ZWjajpekn/4vqf1w6S/ulWYfK/3my77yBgAAJj3CWUwOnd6og6c16J5nt/gxNre9sPcA1bVZWvUr6dgLpCAxNL11nq+kPfYDafdGaaBLuuEi39/swuuluhbpzX8v7XpFWn7dhDwuAAAQL8JZTMxMf3TkTD304nb1T10sucLeT43x5E/87cde9OrbTvuU71P2P1+VbrlM2vqc9J7vSlMP8bcfcqa08HTpvn+V+nfH9ngAAMDEIJzF6M2LZyhbKOqR/tl+wmgHBZTObTZ3mTT98FffPnWhdMx7pd9fLT33S+ktX5YOHbbr08xXz3q3Sw99PZbHAQAAJg7hLEYnLJyq5kxSt62rl5J1o/c727jSd+pfMkrVrOSNn5ESaV9ZO/kvX3373OOlxedJD/2X1L01svYDAICJRziLUSoR6PQjpuue57fLzVg8euWsdG6zo/9k73fUvkj61NPSO6/ylbLRnPUlKdfnd28CAIBJi3AWszcvnqFt3QPa0bRI2viE9OwvpRfvldY9Im16yp8G48i3SfVT9n1HTTP2HswkH+CWXuwPDNj5cqSPAQAATJxktRuwv3vT4TMUmLS8cLje2vcT6cb3v3qmJaNMq2hll0tP3OhPXPuOr0ZznwAAYEIRzmI2pdGPFvDV7SfprR9fKQ3slrI94V+3HwXgsLOiWVnLHH/05toHo7k/AAAw4QhnE+CPjpypf77zOW1MzNLs2QvjXdmcJX60gYFuKdMU77oAAEDk6HM2Ad68eIYk6dfPbol/ZbOXSHLSpifjXxcAAIgc4WwCHDajSfOn1uvXz26Of2VzlvjLjSvjXxcAAIgc4WwCmJnOOnKm/ufF7erPFeJdWfMsqWmWtGFlvOsBAACxIJxNkDccOk3ZfFFPrd8V/8rmLKFyBgDAJEU4myBLFrRJkh57pTP+lc1e4gdaz/bEvy4AABApwtkEmdFcp7lt9Vq5rjP+lc1ZIrkiBwUAADAJEc4m0JIFbXrslZ3xr2j2En9JvzMAACYdwtkEWjq/TRt29Wvz7v54V9QyW2qaSb8zAAAmIcLZBFq6wI+fOWH9zqicAQAw6RDOJtDr5rQolbCJ63e27XkOCgAAYJIhnE2gulRCR81umbh+Z64obXoq/nUBAIDIEM4m2JL5bXpy/S7lC8V4VzT7WH9JvzMAACYVwtkEW7pginqzBb2wuTveFbXMkRqn0+8MAIBJhnA2wZaGJ6ONvd+Zmd+1SeUMAIBJhXA2wRZMbdDUxvTE9Dubs0Ta+pyU7Y1/XeV49hdSx/JqtwIAgJpEOJtgZqYl89v02EQcsVk6KGBzDR0U8OwvpBs/IN31hWq3BACAmkQ4q4Il89u0eku3dvXl4l3RnCX+slb6nW14TLr5L6QgIa1fwWk+AAAYBeGsCkr9zp7o6Ix3RS1zpYZ2aePj8a5nLHatl66/wB+kcP7XpWJeeuXharcKAICaQzirgmPmtUmSVsY9UoCZr55V+6CAgW7p+vf5StlFN0pHvl0KktLL91e3XQAA1CDCWRW01qd02Iymiet3tuVZKdcX/7o6lvu//t1D04oF6eYPS1uelt7zXWnmUVKmSZp7vPQS4QwAgJGS1W7AgWrp/Db9+rktcs7JzOJb0ZwlkitIm5+W5i2Lbz0PXy3defnQ9eY50vQjfPXuxd9I5/6btOjNQ7cf/Ebpgf+QBrqkTHN87QIAYJKhclYlSxa0aUdPVq/siPk0F7OX+MsNj8W3jsdv9MHsyLdLF94gvfnvpUPOkPp3SesflU77tHTiX+y5zMGn+dC49qH42gUAwCRE5axKls6fIsmfjPagaY3xrah1ntQwLb5+Z8/fKf33X0oLT5fe/W0pVScdcc5rLzf/JClISS/fJx3+lnjaBgDAJETlrEoOn9mk+lRCj03EQQFzj5dW/9rvQtyX5++QvnmWdP//lTrXvfZ9r31Q+ukHpdnHSBdc74PZWKUbpHkn0O8MAIARCGdVkkwEOmZe68QcFHD656SuTdI9/7D3ebo2+QrY9lXSr/9R+srrpe++XXr0B3t28C/Z+IQ/ArN1vvT+myvrN7bwjdKmJ6S+zvKXBQBgP8VuzSpaumCKvv3AGu3uz6mlLjXqPH3Zgm545BXd+Mg6XXHuYp1x+PTyVzT/ROmky6TfXy0d/SfSQW/Y83bnpFs/LuX6pcvu96e5ePKn0uM/lm79qHTrx6RUg5Sq95fpBmn3RinTIv3Zf0uN08pvk+QPCvjdP0uvPDS2XaEAABwAzDlX7TZEZtmyZW758skzZuODq7fpom/9Xo3phM55/Wy9+7h5OmnhVAWBqXsgrx8+vFbfun+NtnVnlQxMpy1q13c/dGJlK8v2SFed7Pt5/eX/+KBV8uj3fQA7+5+lky8bmu6cPzXG6nukbLeU6/Wn5Mj1SpaQzvyC1L6o8icg1y9duUA64RLp7P+/8vsBAGASMrMVzrlXnUqBylkVveGwdt102Sn66fIO3fbkRt20okPzptTrtMPadefTm9TZm9Pph0/XR888TPc+v0XX3rdG27sHNK0pU/7K0o3SO74m/eCd0m+vlP443MW5c6105xW+inXipXsuYybNP8H/xSFV56t6L98Xz/0DADAJ0eesypYdPFX//KfH6JEvvllfed8SLWxv1E9XdGjZQVP13399qr7/5yfqxIVTdd6xc1QoOt3+1KbKV3bomdLSD0gP/qc/tUaxKP33X0ky6Z1XSUEVXg4LT5c2PSX17pj4dQMAUIOonNWI+nRC71w6V+9cOlfFolMQ7Hli2iNnNevwmU26deV6feDkgypf0Vv+j7TqV9LPPyYd8x5p7QPSef8ltS0Y5yOo0MFvlOSktf8jLX5HddoAAEANoXJWg0YGM0kyM5137Bw98vJOre/c+1BMW3b3a1dfbu93Xt8mvf3fpc1PSr/6knT42dLSiyNodYXmHicl6zmlBgAAIcLZJHLesXMlSb94fMOot3cP5PW2/3xAb//P+7Wte2Dvd3Tk26Rj3ic1zpDe8VXft6xakhlpwUnSyw9Urw0AANQQwtkksmBag5bMb9OtK0cPZ1fdu1pbuwa0ZfeALvnecvXnCnu/s3d9Q/rESql5VjyNLcfBb/QDo/dsG5q2+RnpJ38m/eBdUj5bvbYBADDBCGeTzPlL5uiZjbu1avOeZ/tft6NX33rgJb1r6Vx99YKleryjU5+6caWKxb2cKsXMH8FZCxae7i9ffkDa+oL00w9JV7/B94178TfSg1+rbvsAAJhAhLNJ5m3HzFZg0q0jdm1eecdzCkz6m7OP0NlHz9IXz12sO57apCvvfK5KLS3DnKVSqlG664vSVSdJL9wlvfHT0qeelhafJ/3uX6TtL8azbuekh66Kd2B4AADKEGs4M7Ozzex5M1ttZpePcruZ2dfC258ws+OG3faymT1pZivNbPKcWTZmM5rr9IZD23Xr4xtUOoHwIy/v0G1PbtRlZxyq2a3+5LIfPm2hPnjKQbr2vjX6wcNrq9nk15ZISYedJfVul075qPTJJ6SzviQ1TJXO+RffL+2Xn/JBKmqPfEu66wrpxxdyOg8AQE2ILZyZWULS1yWdI+koSRea2VEjZjtH0qLw71JJV4+4/Uzn3JLRzp57IDtvyRyt3d6rxzt2qVh0+sdfPKPZrXX6yOmHDs5jZvrSO16ns46cob/7+VP6zXObq9jiMXjXN6TPviC95X9Lje1D01tm+6D20u+kJ26Mdp0bn5Du+oI0d5nUs1W6/bPR3j8AABWIs3J2oqTVzrk1zrmspBsknT9invMlfd95D0tqM7PZMbZpv/DW181SOhHo1pUb9LPH1uvJ9bv0N2cfofp0Yo/5EoHpaxcu1VFzWvRXP3pUD724vUotHoN0g1TXMvptyz4szTvBB6meiB7DQLd004ekhmnSRT+Rzrhceupm6cmborl/AAAqFGc4mytp3bDrHeG0sc7jJN1tZivMbMS4Qge21vqUzjxyun7xxAb9y53P6dj5bTr/2JFPrdeYSep7HzpRC6Y26M+/+4j+8NIk3HUXBP6UH/27pF/9bTT3edtnpB1rpHd/yw/cftqnfAC87dPS7tGPhgUAYCLEGc5GO3nWyE5D+5rnVOfccfK7Pv/azE4fdSVml5rZcjNbvnXr1spbO8mcd+xcf9qMrgF96e1HjXri2pJpTRn96JKTNaetTh/6zh+0Yu0kDGgzXye94WPSyh9JL4VjcTrn+4ltfV7qWCF1bR5bv7SV10tP3CCd8Xnp4NP8tETS71ot5PyQVsVifI8FAIB9iHP4pg5J84ddnydpZElir/M450qXW8zsFvndpK8aIds5d62kayVp2bJlMfQYr01nLZ6htoaUzjh8uo4/aMprzj+9OaMf/8XJet+1D+uD1z2iH15ykpbMb4u/oaPI5otKJyv4XXDG56Wnb5FuvFhKN0ndW6TiiNEQUo3S1EOkaYf4y/bDpelH+MtMsz9Vx22f8edWO/1zey477VA/vNVtn/YHCpxEwRYAMPHMxXEEnCQzS0p6QdJZktZLekTSRc65p4fN8zZJH5V0rqSTJH3NOXeimTVKCpxzXeH/v5L0j865O/e1zmXLlrnlyw+cAzu37O5Xa0NKmWTitWcObdzVp/d942Ht7M3q+ktO1uvntUbSlt39OX3yhpVav7NPQWAKTArMXw7ki+rqz6snm1fPQF65gtMbF7XrmouPV2OmzN8Hr/xeeuA//JGcjdOlpplS0wx/zrbOdX5X5Y410o4XpZ0vS8X80LIt83yYK+aly/7HH2wwknPSj97jz7l24Y/9mKPpJh/sUvXVHU0BALBfMbMVox30GFs4C1d6rqSvSEpIus4592Uzu0ySnHPXmJlJ+i9JZ0vqlfQh59xyMztE0i3h3SQlXe+c+/Jrre9AC2eV6tjZq/d942F1D+T1gw+fqGPmtY37Pq/42ZO68ZFXdNbimZIk55wKRaeikzLJQE11STVlkmrMJJUvFPXtB17ScQum6DsfOkHNdalxr39UhZwPaFuf87s+t70g7XhJOvML0qFn7n25rk3SVadIfSN2/1rgg1qyzge1VIO/bGyXZh0jzT5WmrNEap1f2yEu2yt1b5L6dkqF/FBgLYRBtrHdjxzROF0K9hH88wP+wIpsV3jZ40Ny00wfnve1bJz6OqXtq/22Tzf5EN48xx/8EYQVW+d8H8be7X7XeKZZmrrQn7alljgndW/2PziClP+x0DQjntdXIS9lu6UgKSXS/hQ3la6nWJR6tki71ku5Xv+8JlJSIuPv2xX8durfJfV3+v/zfX6c3VRdeFnv32tBIFnCv54s8M9D/RT/Gqtr23Ob9u2UOtdKO9dKuzr8a3jmUb5yXsm2LeT8Z0bpM6R7k38MyYxvWzLj25luDH/ENUnp5hEn+HZD3S2CRPhYkv7/IBneV3h/ifTQc14sSPl+/z7L9fn7KW2XRNr/Bcm9b6NiUerdJnVt9K/xIOGfu0Tad+MIUkPtsGDof+eGtTlsd7ppz+e6UsWC1PmKPzo+mdlze5deI0EqbNM+HtfAbr+t+3aEl51++bo2qa41/Gvxt+1Y47fhjpf8/4mkfz20Hy61L5KmLfKf5T1b/XPVtclfDnRJp31yfI93DKoSziYa4Wzs1u3o1UXfelidPTl978Mn6rgFr71rdG8eenG7Lvzmw7r09EP0hXMXj2mZ257YqE/c8JheN7dV3//QiWptiCmgVWr3Bn9i2oFu/0GQ7R4KIPk+/2GZ6/WXuzf4D24XDpdVP8W/4c38B5wryn/ImT8qNdMy9EGeavAfvtkev45sj7/fVIO/n8G/tvDDu/SBGv7l+/0HU9/Oob9839B6S5e5Xv+h073ZP56xsEBqaPdfcMWclOsPH3t4Obwqubdlm2b4dub6hi3b75+bwQ/RNn+ZqvfLycIPZvPrKH0A9+7w/2d7/fPRMC38m+q/EDvXSttW+VAwmiDlQ2ch60PZyPZb4MPPtMP89muaMfQFGiT97bk+/6W/q0Patc5fDnT5QNo8U2qe7ddRP8VP7+scCh8Du/39JdLhF3z4BTv8iz5Z76d1bfQBc8ca/7oYLlkntc4Lg9pM/3qqa/EBM9Pi2zrQ5ddXusz2+NdZIecffyHnt8PAbql/t7/M9Y7+nCXS/n9XHHotu6J/jda1Dlt/i2/rrg7/nhjZ5SAOFkj1U307urf4HwqjCZJ+m848yj/3vdv9X9+O8LVQ8I8n3RD+6Grwz9n21Xs+jvopPsTm++N7fImMf37Hcv8WDIXBTJP/XDEbeq/v6z1aLgv8e7Vhqn/O041DwXIwsA4Lmck6/xof6PLvy+2r/cnEC/sY93m4Ungsvd6G/1UiWe9/gBVy/n1V+rwuPbaR95vISF/cNP5A+hoIZ3iVDZ19uvCbD2t7d1bf+dAJOuHgqWXfR3+uoLO/cp+cpDs/cfqrTuexL3c/vUl/ff2jOnxms3744ZM0pTFd9vprRq7Pjwe6caW08XFftZH8m95s6M2f7RlWberyyyXr/IdqutH/per9fH07/Rd7/66xtaEUdFINYdUqDDlm/oOpeabUNGvosmHaUNgrXTrnw03XJv9l173Jn74kkQorhnVDv3ZLu3sHg2aj/3Lu3uLvo3uz1L3Vfwim6vf8lewKPhT07xr6y/UM+9UufxkkwnA6dahakmrYs+rVu92Hi9Z5Q7+E2xdJUxb6wLF7gw87uzf4x5XM+Mfe2O4v66f6+9sefoFsW+W/RHI9oz/P6Wapbb5fX+s8/xx0j/jV3d8pZVql+nCb1Lf58OKKYUjK+r98vx87tlQhKV02TfchceqhYVg8ZKjq0Lk2vHzFj0dbClevOt5KfpvUtfjXVSKzZ9Ulmd4zWNW1+vmKhaEAVwgDnTT0Oi69rrK9e4a7/l1++Za5Q89N6zw/rZD1j7P0uEtf9HWt/rmpa/OvjVKVKN/vt11+wLfHFcLAUvDt6e8cCli92334bZwuTTlIajvIX7bO8wcJbXla2vy0f39uecbfT/2UPcN9kPLbO9c39AMpWef7q04/0l9OW+Rf5yXFwlB7s93DfsB1+fvwT9rQcyeFjyHvqz/FsGpdyO657fP9vro2vDKXzPj7KuaGBezsUHsHuofaUCwM/UhomeMvG6b56cWcD5eFbFgxLww9v8WCb1Pph9Hwdg90Df04Kv1QKm2fwfYP+NdL6fVcCpeW8KGo9L5sX+TbV3qsg9s7/MFXzPvHWHp+LBj6k/nPhExLGBKnDIXzQnbo87JUla1v832Ppyz0z0Pp8eSz/jN6+yr/wzrX528vPW/Ns4d+nMWMcIZRbdrVr4u+9bA27erXtz94gk45dFpZy//THc/qG79bo+svOUlvOKz9tRcY4d7nt+gjP1ihQ9ob9cNLTlJ7U43tVqoFxYL/oMn3D/vgCj9ok3X+A6qutXq7EfdHzvkvDxd+YZW+uBJp/4E/luUncte2c2E46PLtHKyi8ZpAlRSLPqyVfvxhVIQz7NWWrn69/5u/17qdvbr2A8t0+uHTx7Tckx27dP7XH9B7l83Xle8+puL1P7Bqmy75/iM6bEaTfvaXp1Z2JCcAAJPM3sIZ34LQjOY63XDpyTp4WqP+7Lo/6A3/9Gv99fWP6tsPvKTHXtmpgXzhVcvkCkX9zc1PqL0poyvG2M9sb05b1K6vXbBUT63fra/c88K47gsAgMkuzvOcYRKZ1pTRjR85RTev6NCjr+zUY6906rYnNkqS0olAR81p0ZL5bVoyv03Hzm/TbU9s0LMbd+uai49Xa/34S9Zved0sXXDCfF3zuxd15pEzKur/BgDA/oDdmtirzbv79dgrO/XoK51aua5TT3bsUl9uqIp27utn6ar3Hx/Z+roH8jr3q/er6Jzu+MQb4zvFBgAANYA+Zxi3fKGoVVu69fi6Tq3Z1qOPnH6IpkXcgX/F2h16zzUP6d3HzdO/vufYSO8bAIBasrdwxm5NjFkyEWjx7BYtnt0S2zqOP2iq/upNh+m/7l2tsxbP1NlHz4ptXQAA1CIOCEDN+cSbF+n1c1v1hVue1Jau/n3O65zTr57ZrM/f9IQeWLVN+1MlGABwYCKcoeakEoH+433Hqmcgr8t+sEIPrNqmYvHVoeu5Tbt18bd/r7/4/nL97LEOXfzt3+tPr3lI972wlZAGAJi06HOGmnXLYx36u58/rd39ec1prdO7j5+ndx83T011Sf37r17QDX94RS31KX3qzYfrT4+fp589tl5X37taG3b1a+mCNn38rEU6Y9F0BUENj3MJADhgcUAAJqX+XEG/emazblrRoftXbR0cSD1fdPrAyQfpk29epLaGoWGfBvIF3bSiQ1fd+6LWd/Zpdmudzn39bL3tmNlaOr9NVssDkgMADiiEM0x6m3b165bH1mvt9h5d8saFOmxG817nzeaLuuOpjfrF4xt13wtblS0UNbetXmcfPUv1qYR29Ga1syer7T1ZdfZmlQgCNWeSaq5LqqnOX7bVp9XelFZ7c0btTRm1N6WVSSY0kC+qP1fQQL6ggVxRA/mi/z9fVDZfVLZQlMk0qzWjWS31mt1ap7aG1GAwdM6peyCv3f159QzkVZdMqCGTUGM6qbpUMDhfsejUny+oL+vvuz6VUGt9ap+VwGLRqeicEoGNKYgWik7d/Xnt7s9pV19OA/mCpjVmNKu1TnWpVw/9U2p7Z29OqUSg+nRCjemEkolgj3kG8kX1ZgvqGcgrVyiq6JwKRb++onMKzFSfTqguFag+lVBdKqFMMpiU4dk5p1zBKV8s+stCUU5SUyZZ1mMqFJ36cgX15wrK5ovKh/eZLzrlCkPX/TqcckX/mpjenNH05oyaM8k91uWc0+7+vDp7s+oeyCsZBEomTKnSZSJQc13lbezL+sv+XHFwWjoZaGpjWm0NKU1pSCsVvi6c88t19efV1Z9X0Tk1Zfx7rSmd3OM1XXo++3IF5QtFNWaSo74W9yWbL6p7IK+EmerSgdKJaF5bzjlt6RrQi1u79eLWHq3Z2q3Nu/uVSgTKJANlkv51XJ/222VGc51mtmQ0s6VO7U0ZFZ171XOWSQZqrkuVvS3Gq1h06snmB7dJ90BOPQMF1aUSago/C1vqUmrM7Pn+Hot8oajeXEG9AwU5ObXWp1SfSpT92Eqvm54B/3rryebVmy0Mvh9yRX9ZKBZVn06qpS6p1vqUWutTaqlPDb7+ahnhDAes3f05/erpzbrtyY26f9VWFYpOUxrSmtqY1pTGtKY0pFQoSl39OXUPlD6sfFgZpatbRepSgaY2pNWTLairf+/3ayY1pBLKFZ2y+eKrbg9Maq1Phe32FcOu/py6Sx+w2bxKb+lUwpQMAqUSpsQogS5fcOoayO+1zS11Sc1qrdPUxrS6+vPaEYbZ0dqVTgZqSCeULzj1ZvMVP2/JwPYIEIkgeNUQlc7Jh5ZCGFqKToW9rDAwf5RxKjB/mTAVik75otsj7JhpcJ3JwAY/1Ev3X/oiKPfjMpUwNdel1JRJqjGTVLE4/AvFt7/0ZZ0tvPp5LUddKtD05owyyYQ6e7Pa2Zvb6/My1jbmC0Xlik4DFbaxOeODV/dAfp9tKQXZ/lxB/fniq+ZNJ4LBH00N6aRGfucWi1JvNj/4o2fkazQwqS6VUH0Y8sayXUuvnWQw9JrozxXUkx0612N9KqHZbXUqFl34I62ogVxBfblCRe+B0rZIJcYWYkw2GLST4Wtc0mAbSgFwYJT3bDmv5WTgP0NSiaH3SDBK0MoViurJFkb9jEglTC11PjRlkoEG8kUf8MMfoKO9tsYbTxLDtl1y2Odh6f/Sc5YI/HM5XDoZ6Oa/fMP4GjAGnEoDB6yWupTvr3b8PGXzRf/BMoZ+aIWi087erLZ3Z7Wte0Dbugc0kC8OVnlKl5lkoHRy6JdzOhmoUHTatLtfm3b1a+Oufm3a1aftPVk1ZfyvUf/Lzn/RZPNF9Wbz6gkrTb3ZgpIJU334ZVJaT1+uoJ09/ku3VPmTpPb2RjVl/C/v5rqkUolg8Es1lx8KLyM/SxPB0IdlS11SLfUppZOBtndntXl3v7bs7tem3f3a0ZPVzJY6LZ7dommNYahtSKvg3GB7/Z+vzjRmEmFFLan69FBFLGGmRCAF5gOS/1D24aQv/ALJF0ZWikb/dE6N+KBNBIFGblEnjRo0EmaDXzCl4OakwapXvuhDm3Pa40svlRj9C2mwPeG8pWA3VJXw4bl7oKBEMBQWE2H768JtXJ9KqD7tX1fpRDDiyzAYXEcpaCYTpv5sQVu6BrS1a0Bbuvq1tcu/Rks/OqY0+G3VmEmGoXSoupctFMOKyd7bWHpMo7Vx8Hr4f13Kf+HuCKvRO3py2tmbVdG58LXpX6NNmaQSgYXr82Gqqz83WB2uD++rLpVQMrDwB42v7HSF1eaRX9pmUkN6qOrdnPHrKTjtUeXrDU+iPfw5TAXBqJ8HxcEQP/SaSCUCLWxv1CHtTTpkeqNmtdTtddntPeH7qKtfm3b5z49kwlSX9O+P+vB9PZAvqqs/p93DtkW+MLZUUnSlgOmrR7mCk3PyVemwglef8p9JI1tpZoMVsqZw+zSmE+rP+fZ09efVFbYnGwbm4RVi/w4bUnq/lPYCNKQTakj7iFGqzO/u85f9ueKY2igzNYTV+YbwPuvT/v2RHBYUE4GpL1sYtp784J4A/yNuz9d+oeifs3zBTyuOkgLTVa66Ec5wQClnUPVEYOHuzIyO0N53oe7NnLb6spcBMPkFgQ3ubpZaq90cTEK1v0MWAADgAEI4AwAAqCGEMwAAgBpCOAMAAKghhDMAAIAaQjgDAACoIYQzAACAGkI4AwAAqCGEMwAAgBpCOAMAAKghhDMAAIAaQjgDAACoIYQzAACAGkI4AwAAqCGEMwAAgBpCOAMAAKghhDMAAIAaQjgDAACoIeacq3YbImNmWyWtjXk17ZK2xbwOlI/tUrvYNrWJ7VK72Da1KY7tcpBzbvrIiftVOJsIZrbcObes2u3AntgutYttU5vYLrWLbVObJnK7sFsTAACghhDOAAAAagjhrHzXVrsBGBXbpXaxbWoT26V2sW1q04RtF/qcAQAA1BAqZwAAADWEcDZGZna2mT1vZqvN7PJqt+dAZmbzzexeM3vWzJ42s0+E06ea2a/MbFV4OaXabT0QmVnCzB4zs1+G19kuNcDM2szsJjN7LnzvnMK2qT4z+1T4OfaUmf3YzOrYLtVhZteZ2RYze2rYtL1uCzO7IswEz5vZW6NsC+FsDMwsIenrks6RdJSkC83sqOq26oCWl/QZ59xiSSdL+utwe1wu6dfOuUWSfh1ex8T7hKRnh11nu9SGr0q60zl3pKRj5bcR26aKzGyupI9LWuacO1pSQtIFYrtUy3clnT1i2qjbIvzOuUDS68JlrgqzQiQIZ2NzoqTVzrk1zrmspBsknV/lNh2wnHMbnXOPhv93yX/JzJXfJt8LZ/uepHdWpYEHMDObJ+ltkr41bDLbpcrMrEXS6ZK+LUnOuaxzrlNsm1qQlFRvZklJDZI2iO1SFc65+yTtGDF5b9vifEk3OOcGnHMvSVotnxUiQTgbm7mS1g273hFOQ5WZ2cGSlkr6vaSZzrmNkg9wkmZUsWkHqq9I+htJxWHT2C7Vd4ikrZK+E+5y/paZNYptU1XOufWS/k3SK5I2StrlnLtbbJdasrdtEWsuIJyNjY0yjcNcq8zMmiTdLOmTzrnd1W7Pgc7M3i5pi3NuRbXbgldJSjpO0tXOuaWSesSusqoL+y+dL2mhpDmSGs3s4uq2CmMUay4gnI1Nh6T5w67Pky89o0rMLCUfzH7knPtZOHmzmc0Ob58taUu12neAOlXSeWb2svyu/z8ysx+K7VILOiR1OOd+H16/ST6ssW2q682SXnLObXXO5ST9TNIbxHapJXvbFrHmAsLZ2DwiaZGZLTSztHwnwFur3KYDlpmZfN+ZZ51z/z7splslfTD8/4OSfj7RbTuQOeeucM7Nc84dLP8e+Y1z7mKxXarOObdJ0jozOyKcdJakZ8S2qbZXJJ1sZg3h59pZ8n1o2S61Y2/b4lZJF5hZxswWSlok6Q9RrZST0I6RmZ0r358mIek659yXq9uiA5eZnSbpfklPaqhv0xfk+539RNIC+Q+99zjnRnbuxAQwszdJ+qxz7u1mNk1sl6ozsyXyB2qkJa2R9CH5H+hsmyoys3+Q9D75o9Afk3SJpCaxXSacmf1Y0psktUvaLOnvJP239rItzOyLkv5cftt90jl3R2RtIZwBAADUDnZrAgAA1BDCGQAAQA0hnAEAANQQwhkAAEANIZwBAADUEMIZgP2emf2Tmb3JzN5pZhNyZnwze9nM2idiXQD2L4QzAAeCk+TPg3eG/DnyAKBmEc4A7LfM7F/N7AlJJ0h6SP4En1eb2ZfM7FAzu9PMVpjZ/WZ2ZLjMd83smnDaC+GYoTKzOjP7jpk9GQ4efmY4PWFm/xZOf8LMPjasCR8zs0fD246c4IcPYJJKVrsBABAX59znzOynkj4g6dOSfuucO1WSzOzXki5zzq0ys5MkXSXpj8JFD5avsh0q6V4zO0zSX4f3+fowaN1tZofLn2l/oaSlzrm8mU0d1oRtzrnjzOyvJH1WPhwCwD4RzgDs75ZKWinpSPnxJGVmTfIDTP/UD2koScoMW+YnzrmipFVmtiZc9jRJ/ylJzrnnzGytpMPlB6++xjmXD28bPszOz8LLFZL+JPJHBmC/RDgDsF8Kx5L8rqR5krZJavCTbaV8VazTObdkL4uPHNfOSbLRZgyn720cvIHwsiA+bwGMEX3OAOyXnHMrw/D1gqSjJP1G0ludc0ucc7skvWRm75F8YjOzY4ct/h4zC8zsUEmHSHpe0n2S3h/Of7j8QMjPS7pb0mVmlgxvG75bEwDKRjgDsN8ys+mSdoa7KI90zj0z7Ob3S/qwmT0u6WlJ5w+77XlJv5N0h3y/tH75PmkJM3tS0o2S/pdzbkDStyS9IumJ8L4uivtxAdi/mXN7q8YDwIHHzL4r6ZfOuZuq3RYAByYqZwAAADWEyhkAAEANoXIGAABQQwhnAAAANYRwBgAAUEMIZwAAADWEcAYAAFBDCGcAAAA15P8BuQglAkWtupQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize loss\n",
    "plt.figure(figsize=(10, 8))\n",
    "    \n",
    "plt.title(\"Training loss\")\n",
    "plt.xlabel(\"#epoch\")\n",
    "plt.ylabel(\"loss\")\n",
    "\n",
    "plt.plot(loss_curve_train, label='train')\n",
    "plt.plot(loss_curve_test, label='test')\n",
    "\n",
    "\n",
    "#plt.yscale('log',base=2)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict, Counter\n",
    "\n",
    "val_loader = DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=4)\n",
    "\n",
    "im_by_cer = defaultdict(list)\n",
    "cnt = Counter()\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for data, target in val_loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        preds = model(data)\n",
    "        label = alphabet.decode(target)[0]\n",
    "        pred_label = alphabet.decode(preds)[0]\n",
    "        cer = character_error_rate(pred_label, label)\n",
    "        im_by_cer[cer].append((label, pred_label))\n",
    "        cnt[cer] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0.0: 169, 0.2: 40, 0.4: 5})\n"
     ]
    }
   ],
   "source": [
    "print(cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRUE        PRED        ERROR\n",
      "------------------------------------\n",
      "xemyg       xenyp       m-->n   g-->p   \n",
      "\n",
      "dnmd8       gpmd8       d-->g   n-->p   \n",
      "\n",
      "wce5n       wye5m       c-->y   n-->m   \n",
      "\n",
      "46mbm       46nbn       m-->n   m-->n   \n",
      "\n",
      "p6mn8       p6nm8       m-->n   n-->m   \n",
      "\n",
      "n265y       n268y       5-->8   \n",
      "\n",
      "24f6w       24f5w       6-->5   \n",
      "\n",
      "8gecm       8gecn       m-->n   \n",
      "\n",
      "n2gmg       n2gwg       m-->w   \n",
      "\n",
      "pnnwy       pnnyy       w-->y   \n",
      "\n",
      "d3ycn       g3ycn       d-->g   \n",
      "\n",
      "d8xcn       d8ycn       x-->y   \n",
      "\n",
      "xxney       xxnex       y-->x   \n",
      "\n",
      "w8bnx       w8pnx       b-->p   \n",
      "\n",
      "6pwcn       6pwcm       n-->m   \n",
      "\n",
      "2mpnn       2mpnm       n-->m   \n",
      "\n",
      "c86md       c86nd       m-->n   \n",
      "\n",
      "3c7de       3c78e       d-->8   \n",
      "\n",
      "n7meb       n7neb       m-->n   \n",
      "\n",
      "d7en3       g7en3       d-->g   \n",
      "\n",
      "gdng3       gdnn3       g-->n   \n",
      "\n",
      "6m5eg       6n5eg       m-->n   \n",
      "\n",
      "n5n8b       n5n8p       b-->p   \n",
      "\n",
      "c2fb7       c2fp7       b-->p   \n",
      "\n",
      "xxbm5       xxbn5       m-->n   \n",
      "\n",
      "3x5fm       3x5fn       m-->n   \n",
      "\n",
      "b2g8e       b3g8e       2-->3   \n",
      "\n",
      "excmn       excnn       m-->n   \n",
      "\n",
      "yf347       xf347       y-->x   \n",
      "\n",
      "neecd       neecf       d-->f   \n",
      "\n",
      "yyg5g       xyg5g       y-->x   \n",
      "\n",
      "bc8nf       bc8mf       n-->m   \n",
      "\n",
      "5p8fm       5p8fn       m-->n   \n",
      "\n",
      "f85y3       f85x3       y-->x   \n",
      "\n",
      "5mf7c       5nf7c       m-->n   \n",
      "\n",
      "fncnb       fncdb       n-->d   \n",
      "\n",
      "3bx86       3by86       x-->y   \n",
      "\n",
      "ypw3d       ypw38       d-->8   \n",
      "\n",
      "66wp5       66wp6       5-->6   \n",
      "\n",
      "yfdn7       yfdm7       n-->m   \n",
      "\n",
      "m8gmx       m8gmn       x-->n   \n",
      "\n",
      "43p5d       43g5d       p-->g   \n",
      "\n",
      "dpbyd       dpbxd       y-->x   \n",
      "\n",
      "7yf62       7yf52       6-->5   \n",
      "\n",
      "ep85x       cp85x       e-->c   \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('TRUE        PRED        ERROR')\n",
    "print('------------------------------------')\n",
    "for cer in cnt.keys():\n",
    "    if cer == 0.: continue\n",
    "    for true_lbl, pred_lbl in im_by_cer[cer]:\n",
    "        print(f'{true_lbl}       {pred_lbl}', end='       ')\n",
    "        [print('-->'.join([a, b]), end='   ') for a, b in zip(true_lbl, pred_lbl) if a != b]\n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##### Видно, что большинство ошибок предсказуемы - замена 'n' на 'm', 'c' на 'e', '6' на '8' и т.п."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
