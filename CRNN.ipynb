{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import random\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, ColorJitter, Compose, Normalize\n",
    "\n",
    "from torch import nn\n",
    "from torch.nn import Module\n",
    "from torch.nn import Conv2d\n",
    "from torch.nn import Linear\n",
    "from torch.nn import ReLU\n",
    "from torch.nn import LogSoftmax\n",
    "from torch.nn import BatchNorm2d\n",
    "from torch.nn import LSTM\n",
    "from torch import flatten\n",
    "from torchmetrics import CharErrorRate\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import CTCLoss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alphabet class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Alphabet(object):\n",
    "    def __init__(self, folder_path):\n",
    "        self.symbol2idx = {}\n",
    "        self.idx2symbol = []\n",
    "        self._len = 0\n",
    "        self.make_alphabet(folder_path)\n",
    "        \n",
    "    def add_symbol(self, s):\n",
    "        if s not in self.symbol2idx:\n",
    "            self.idx2symbol.append(s)\n",
    "            self.symbol2idx[s] = self._len\n",
    "            self._len += 1\n",
    "            \n",
    "    def make_alphabet(self, folder_path):\n",
    "        assert os.path.exists(folder_path)\n",
    "        for _, _, files in os.walk(folder_path):\n",
    "            for file_name in files:\n",
    "                file_name = file_name.split('.')[0]\n",
    "                for symbol in file_name:\n",
    "                    self.add_symbol(symbol)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self._len\n",
    "    \n",
    "    def encode(self, label):\n",
    "        ids = torch.zeros([len(label), len(self)], dtype=torch.float32)\n",
    "        for pos, symbol in enumerate(label):\n",
    "            ids[pos, self.symbol2idx[symbol]] = 1.\n",
    "        return ids\n",
    "    \n",
    "    def decode(self, ids):\n",
    "        idxs = ids.argmax(dim=2).tolist()\n",
    "        labels = [''.join([self.idx2symbol[i] for i in b]) for b in idxs]\n",
    "        return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dir = './samples/'\n",
    "\n",
    "alphabet = Alphabet(img_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, img_dir, transform=None):\n",
    "        self.img_labels = []\n",
    "        for _, _, files in os.walk(img_dir):\n",
    "            for file_ in files:\n",
    "                self.img_labels.append(file_)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        filename = self.img_labels[idx]\n",
    "        img_path = os.path.join(self.img_dir, filename)\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        label = alphabet.encode(filename.split('.')[0])\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_files = []\n",
    "for _, _, files in os.walk(img_dir):\n",
    "    for file_ in files:\n",
    "        all_files.append(file_)\n",
    "        \n",
    "random.shuffle(all_files)\n",
    "border = int(0.8 * len(all_files))\n",
    "train_files = all_files[:border]\n",
    "test_files = all_files[border:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_dir = 'data/train/'\n",
    "test_data_dir = 'data/test/'\n",
    "\n",
    "if not os.path.exists(train_data_dir):\n",
    "    os.makedirs(train_data_dir)\n",
    "    for file in train_files:\n",
    "        shutil.copy(os.path.join(img_dir, file), train_data_dir)\n",
    "\n",
    "if not os.path.exists(test_data_dir):\n",
    "    os.makedirs(test_data_dir)\n",
    "    for file in test_files:\n",
    "        shutil.copy(os.path.join(img_dir, file), test_data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find mean and std of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CustomImageDataset(img_dir=train_data_dir,\n",
    "                                   transform=Compose([\n",
    "                                            #ColorJitter(),\n",
    "                                            ToTensor(),\n",
    "                                   ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = DataLoader(dataset, batch_size=32, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.7151, 0.7151, 0.7151])\n",
      "tensor([0.3136, 0.3136, 0.3136])\n"
     ]
    }
   ],
   "source": [
    "nimages = 0\n",
    "mean = 0.0\n",
    "var = 0.0\n",
    "for i_batch, batch_target in enumerate(data_loader):\n",
    "    batch = batch_target[0]\n",
    "    # Rearrange batch to be the shape of [B, C, W * H]\n",
    "    batch = batch.view(batch.size(0), batch.size(1), -1)\n",
    "    # Update total number of images\n",
    "    nimages += batch.size(0)\n",
    "    # Compute mean and std here\n",
    "    mean += batch.mean(2).sum(0) \n",
    "    var += batch.var(2).sum(0)\n",
    "\n",
    "mean /= nimages\n",
    "var /= nimages\n",
    "std = torch.sqrt(var)\n",
    "\n",
    "print(mean)\n",
    "print(std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomImageDataset(img_dir=train_data_dir,\n",
    "                                   transform=Compose([\n",
    "                                            #ColorJitter(),\n",
    "                                            ToTensor(),\n",
    "                                            Normalize(mean=[0.7152, 0.7152, 0.7152], std=[0.3136, 0.3136, 0.3136]),\n",
    "                                   ]))\n",
    "\n",
    "test_dataset = CustomImageDataset(img_dir=test_data_dir,\n",
    "                                  transform=Compose([\n",
    "                                            ToTensor(),\n",
    "                                            Normalize(mean=[0.7152, 0.7152, 0.7152], std=[0.3136, 0.3136, 0.3136]),\n",
    "                                 ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bidirectional_LSTM(torch.nn.Module):\n",
    "    def __init__(self, class_num, hidden_unit):\n",
    "        super(Bidirectional_LSTM, self).__init__()\n",
    "        \n",
    "        self.LSTM1 = torch.nn.LSTM(1024, hidden_unit, bidirectional=True)\n",
    "        self.embedding1 = torch.nn.Linear(hidden_unit * 2, 1024)\n",
    "        self.LSTM2 = torch.nn.LSTM(1024, hidden_unit, bidirectional=True)\n",
    "        self.embedding2 = torch.nn.Linear(hidden_unit * 2, class_num)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.LSTM1(x)   # LSTM output: output, (h_n, c_n)\n",
    "        T, b, h = x[0].size()   # x[0]: (seq_len, batch, num_directions * hidden_size)\n",
    "        x = self.embedding1(x[0].view(T * b, h))  # pytorch view() reshape as [T * b, nOut]\n",
    "        x = x.view(T, b, -1)  # [seq_len, b, 512]\n",
    "        \n",
    "        x = self.LSTM2(x)\n",
    "        T, b, h = x[0].size()\n",
    "        x = self.embedding2(x[0].view(T * b, h))\n",
    "        x = x.view(T, b, -1)\n",
    "        \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CapchaNet(Module):\n",
    "    def __init__(self, alphabet_len):\n",
    "        super(CapchaNet, self).__init__()\n",
    "        \n",
    "        self.conv1 = Conv2d(3, 128, (3, 3), stride=2) # 99x24\n",
    "        self.bn1 = BatchNorm2d(128)\n",
    "        self.conv2 = Conv2d(128, 256, (3, 3), stride=2) # 48x11\n",
    "        self.bn2 = BatchNorm2d(256)\n",
    "        self.conv3 = Conv2d(256, 512, (3, 3), stride=2) # 23x5\n",
    "        self.bn3 = BatchNorm2d(512)\n",
    "        self.conv4 = Conv2d(512, 1024, (3, 3), stride=2) # 11x2\n",
    "        self.bn4 = BatchNorm2d(1024)\n",
    "        self.conv5 = Conv2d(1024, 1024, (2, 2), stride=(1, 2)) # 5X1\n",
    "        self.bn5 = BatchNorm2d(1024)\n",
    "        self.rnn = Bidirectional_LSTM(alphabet_len, 1024)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.bn1(F.relu(self.conv1(x)))\n",
    "        x = self.bn2(F.relu(self.conv2(x)))\n",
    "        x = self.bn3(F.relu(self.conv3(x)))\n",
    "        x = self.bn4(F.relu(self.conv4(x)))\n",
    "        x = self.bn5(F.relu(self.conv5(x)))\n",
    "        \n",
    "        x = x.squeeze(2)  # remove h dimension\n",
    "        x = x.permute(2, 0, 1)  # [w, b, c] = [seq_len, batch, input_size]\n",
    "        x = self.rnn(x)\n",
    "        \n",
    "        x = x.permute(1, 0, 2)\n",
    "        output = F.log_softmax(x, dim=2)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import math\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "ntokens = len(alphabet)\n",
    "model = CapchaNet(ntokens)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "grad_clip = 0.1\n",
    "lr = torch.tensor(1e-3)\n",
    "optim = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "scheduler = lr_scheduler.ReduceLROnPlateau(optim, mode='min',\n",
    "                                           factor=0.4, patience=3, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lr(optimizer):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        return param_group['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def character_error_rate(preds, labels):\n",
    "    assert len(preds) == len(labels)\n",
    "    errors = 0\n",
    "    for pred, label in zip(preds, labels):\n",
    "        for p, l in zip(pred, label):\n",
    "            errors += int(p != l)\n",
    "    return errors / (len(labels) * len(labels[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model):\n",
    "    \n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    total_val_loss = 0\n",
    "    cer, cer_p = 0, 0\n",
    "    CER = CharErrorRate()\n",
    "    for data, targets in train_loader:\n",
    "        \n",
    "        output = model(data)\n",
    "        optim.zero_grad()\n",
    "        loss = criterion(output, targets)\n",
    "        loss.backward()\n",
    "\n",
    "        # torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n",
    "        optim.step()\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for data, targets in test_loader:\n",
    "            preds = model(data)\n",
    "            val_loss = criterion(preds, targets)\n",
    "            total_val_loss += val_loss.item()\n",
    "            labels = alphabet.decode(targets)\n",
    "            pred_labels = alphabet.decode(preds)\n",
    "            cer_p += CER(pred_labels, labels)\n",
    "            cer += character_error_rate(pred_labels, labels)\n",
    "            \n",
    "    \n",
    "    total_loss /= len(train_loader)\n",
    "    total_val_loss /= len(test_loader)\n",
    "    cer /= len(test_loader)\n",
    "    cer_p /= len(test_loader)\n",
    "    \n",
    "    scheduler.step(total_val_loss)\n",
    "    \n",
    "    print('[Epoch {:3d}]:  lr {:02.6f} | train loss {:5.5f} | val loss {:5.5f} | val CER {:5.5f} | val CER(torch) {:5.5f}'.format(\n",
    "                epoch, get_lr(optim), total_loss, total_val_loss, cer, cer_p))\n",
    "    return total_loss, total_val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_curve_train, loss_curve_test = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch   1]:  lr 0.001000 | train loss 0.28199 | val loss 0.21414 | val CER 0.69984 | val CER(torch) 0.69840\n",
      "[Epoch   2]:  lr 0.001000 | train loss 0.12441 | val loss 0.17204 | val CER 0.58098 | val CER(torch) 0.58050\n",
      "[Epoch   3]:  lr 0.001000 | train loss 0.09095 | val loss 0.07357 | val CER 0.26384 | val CER(torch) 0.26384\n",
      "[Epoch   4]:  lr 0.001000 | train loss 0.07215 | val loss 0.07695 | val CER 0.27089 | val CER(torch) 0.27089\n",
      "[Epoch   5]:  lr 0.001000 | train loss 0.06585 | val loss 0.06449 | val CER 0.21912 | val CER(torch) 0.21912\n",
      "[Epoch   6]:  lr 0.001000 | train loss 0.05569 | val loss 0.04782 | val CER 0.13691 | val CER(torch) 0.13691\n",
      "[Epoch   7]:  lr 0.001000 | train loss 0.05223 | val loss 0.05916 | val CER 0.18216 | val CER(torch) 0.18216\n",
      "[Epoch   8]:  lr 0.001000 | train loss 0.05338 | val loss 0.05944 | val CER 0.18114 | val CER(torch) 0.18114\n",
      "[Epoch   9]:  lr 0.001000 | train loss 0.05281 | val loss 0.04726 | val CER 0.11506 | val CER(torch) 0.11506\n",
      "[Epoch  10]:  lr 0.001000 | train loss 0.04876 | val loss 0.04432 | val CER 0.09647 | val CER(torch) 0.09647\n",
      "[Epoch  11]:  lr 0.001000 | train loss 0.04816 | val loss 0.04695 | val CER 0.11832 | val CER(torch) 0.11832\n",
      "[Epoch  12]:  lr 0.001000 | train loss 0.05035 | val loss 0.04899 | val CER 0.13515 | val CER(torch) 0.13515\n",
      "[Epoch  13]:  lr 0.001000 | train loss 0.05244 | val loss 0.05003 | val CER 0.12415 | val CER(torch) 0.12415\n",
      "[Epoch  14]:  lr 0.001000 | train loss 0.04897 | val loss 0.04180 | val CER 0.06234 | val CER(torch) 0.06234\n",
      "[Epoch  15]:  lr 0.001000 | train loss 0.04583 | val loss 0.04398 | val CER 0.08819 | val CER(torch) 0.08819\n",
      "[Epoch  16]:  lr 0.001000 | train loss 0.04296 | val loss 0.04053 | val CER 0.05775 | val CER(torch) 0.05775\n",
      "[Epoch  17]:  lr 0.001000 | train loss 0.04290 | val loss 0.04205 | val CER 0.06784 | val CER(torch) 0.06784\n",
      "[Epoch  18]:  lr 0.001000 | train loss 0.04511 | val loss 0.04255 | val CER 0.06378 | val CER(torch) 0.06378\n",
      "[Epoch  19]:  lr 0.001000 | train loss 0.04196 | val loss 0.04083 | val CER 0.04615 | val CER(torch) 0.04615\n",
      "Epoch 00020: reducing learning rate of group 0 to 4.0000e-04.\n",
      "[Epoch  20]:  lr 0.000400 | train loss 0.04172 | val loss 0.04199 | val CER 0.05844 | val CER(torch) 0.05844\n",
      "[Epoch  21]:  lr 0.000400 | train loss 0.04078 | val loss 0.03930 | val CER 0.03248 | val CER(torch) 0.03248\n",
      "[Epoch  22]:  lr 0.000400 | train loss 0.03963 | val loss 0.03868 | val CER 0.02959 | val CER(torch) 0.02959\n",
      "[Epoch  23]:  lr 0.000400 | train loss 0.03897 | val loss 0.03855 | val CER 0.02815 | val CER(torch) 0.02815\n",
      "[Epoch  24]:  lr 0.000400 | train loss 0.03890 | val loss 0.03851 | val CER 0.02671 | val CER(torch) 0.02671\n",
      "[Epoch  25]:  lr 0.000400 | train loss 0.03952 | val loss 0.03853 | val CER 0.02719 | val CER(torch) 0.02719\n",
      "[Epoch  26]:  lr 0.000400 | train loss 0.03883 | val loss 0.03852 | val CER 0.02479 | val CER(torch) 0.02479\n",
      "[Epoch  27]:  lr 0.000400 | train loss 0.03908 | val loss 0.03847 | val CER 0.02431 | val CER(torch) 0.02431\n",
      "[Epoch  28]:  lr 0.000400 | train loss 0.03855 | val loss 0.03847 | val CER 0.02431 | val CER(torch) 0.02431\n",
      "[Epoch  29]:  lr 0.000400 | train loss 0.03893 | val loss 0.03848 | val CER 0.02286 | val CER(torch) 0.02286\n",
      "[Epoch  30]:  lr 0.000400 | train loss 0.03867 | val loss 0.03846 | val CER 0.02334 | val CER(torch) 0.02334\n",
      "[Epoch  31]:  lr 0.000400 | train loss 0.03879 | val loss 0.03846 | val CER 0.02286 | val CER(torch) 0.02286\n",
      "[Epoch  32]:  lr 0.000400 | train loss 0.03918 | val loss 0.03844 | val CER 0.02238 | val CER(torch) 0.02238\n",
      "[Epoch  33]:  lr 0.000400 | train loss 0.03909 | val loss 0.03845 | val CER 0.02238 | val CER(torch) 0.02238\n",
      "[Epoch  34]:  lr 0.000400 | train loss 0.03891 | val loss 0.03844 | val CER 0.02286 | val CER(torch) 0.02286\n",
      "[Epoch  35]:  lr 0.000400 | train loss 0.03904 | val loss 0.03844 | val CER 0.02190 | val CER(torch) 0.02190\n",
      "Epoch 00036: reducing learning rate of group 0 to 1.6000e-04.\n",
      "[Epoch  36]:  lr 0.000160 | train loss 0.03903 | val loss 0.03844 | val CER 0.02238 | val CER(torch) 0.02238\n",
      "[Epoch  37]:  lr 0.000160 | train loss 0.03961 | val loss 0.03841 | val CER 0.02190 | val CER(torch) 0.02190\n",
      "[Epoch  38]:  lr 0.000160 | train loss 0.03890 | val loss 0.03842 | val CER 0.02094 | val CER(torch) 0.02094\n",
      "[Epoch  39]:  lr 0.000160 | train loss 0.03916 | val loss 0.03843 | val CER 0.02142 | val CER(torch) 0.02142\n",
      "[Epoch  40]:  lr 0.000160 | train loss 0.03890 | val loss 0.03840 | val CER 0.02238 | val CER(torch) 0.02238\n",
      "[Epoch  41]:  lr 0.000160 | train loss 0.03863 | val loss 0.03843 | val CER 0.02286 | val CER(torch) 0.02286\n",
      "[Epoch  42]:  lr 0.000160 | train loss 0.03916 | val loss 0.03841 | val CER 0.02238 | val CER(torch) 0.02238\n",
      "[Epoch  43]:  lr 0.000160 | train loss 0.03863 | val loss 0.03842 | val CER 0.02286 | val CER(torch) 0.02286\n",
      "Epoch 00044: reducing learning rate of group 0 to 6.4000e-05.\n",
      "[Epoch  44]:  lr 0.000064 | train loss 0.03876 | val loss 0.03841 | val CER 0.02094 | val CER(torch) 0.02094\n",
      "[Epoch  45]:  lr 0.000064 | train loss 0.03876 | val loss 0.03841 | val CER 0.02142 | val CER(torch) 0.02142\n",
      "[Epoch  46]:  lr 0.000064 | train loss 0.03902 | val loss 0.03842 | val CER 0.02142 | val CER(torch) 0.02142\n",
      "[Epoch  47]:  lr 0.000064 | train loss 0.03934 | val loss 0.03841 | val CER 0.02190 | val CER(torch) 0.02190\n",
      "Epoch 00048: reducing learning rate of group 0 to 2.5600e-05.\n",
      "[Epoch  48]:  lr 0.000026 | train loss 0.03907 | val loss 0.03841 | val CER 0.02142 | val CER(torch) 0.02142\n",
      "[Epoch  49]:  lr 0.000026 | train loss 0.03929 | val loss 0.03841 | val CER 0.02046 | val CER(torch) 0.02046\n",
      "[Epoch  50]:  lr 0.000026 | train loss 0.03916 | val loss 0.03841 | val CER 0.02142 | val CER(torch) 0.02142\n",
      "[Epoch  51]:  lr 0.000026 | train loss 0.03894 | val loss 0.03841 | val CER 0.02142 | val CER(torch) 0.02142\n",
      "Epoch 00052: reducing learning rate of group 0 to 1.0240e-05.\n",
      "[Epoch  52]:  lr 0.000010 | train loss 0.03907 | val loss 0.03842 | val CER 0.02142 | val CER(torch) 0.02142\n",
      "[Epoch  53]:  lr 0.000010 | train loss 0.03876 | val loss 0.03841 | val CER 0.02238 | val CER(torch) 0.02238\n",
      "[Epoch  54]:  lr 0.000010 | train loss 0.03925 | val loss 0.03842 | val CER 0.02190 | val CER(torch) 0.02190\n",
      "[Epoch  55]:  lr 0.000010 | train loss 0.03978 | val loss 0.03842 | val CER 0.02190 | val CER(torch) 0.02190\n",
      "Epoch 00056: reducing learning rate of group 0 to 4.0960e-06.\n",
      "[Epoch  56]:  lr 0.000004 | train loss 0.03876 | val loss 0.03840 | val CER 0.02190 | val CER(torch) 0.02190\n",
      "[Epoch  57]:  lr 0.000004 | train loss 0.03849 | val loss 0.03840 | val CER 0.02190 | val CER(torch) 0.02190\n",
      "[Epoch  58]:  lr 0.000004 | train loss 0.03907 | val loss 0.03840 | val CER 0.02094 | val CER(torch) 0.02094\n",
      "[Epoch  59]:  lr 0.000004 | train loss 0.03849 | val loss 0.03839 | val CER 0.02094 | val CER(torch) 0.02094\n",
      "[Epoch  60]:  lr 0.000004 | train loss 0.03876 | val loss 0.03841 | val CER 0.02238 | val CER(torch) 0.02238\n",
      "[Epoch  61]:  lr 0.000004 | train loss 0.03863 | val loss 0.03841 | val CER 0.02238 | val CER(torch) 0.02238\n",
      "[Epoch  62]:  lr 0.000004 | train loss 0.03881 | val loss 0.03839 | val CER 0.02046 | val CER(torch) 0.02046\n",
      "Epoch 00063: reducing learning rate of group 0 to 1.6384e-06.\n",
      "[Epoch  63]:  lr 0.000002 | train loss 0.03942 | val loss 0.03839 | val CER 0.02190 | val CER(torch) 0.02190\n",
      "CPU times: user 2h 17min 48s, sys: 10min 4s, total: 2h 27min 52s\n",
      "Wall time: 24min 48s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for epoch in range(1, 65):\n",
    "    train_loss, test_loss = train(model)\n",
    "    loss_curve_train.append(train_loss)\n",
    "    loss_curve_test.append(test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize loss\n",
    "plt.figure(figsize=(10, 8))\n",
    "    \n",
    "plt.title(\"Training loss\")\n",
    "plt.xlabel(\"#epoch\")\n",
    "plt.ylabel(\"loss\")\n",
    "\n",
    "plt.plot(loss_curve_train, label='train')\n",
    "plt.plot(loss_curve_test, label='test')\n",
    "\n",
    "\n",
    "#plt.yscale('log',base=2)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict, Counter\n",
    "\n",
    "val_loader = DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=4)\n",
    "\n",
    "im_by_cer = defaultdict(list)\n",
    "cnt = Counter()\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for data, target in val_loader:\n",
    "        preds = model(data)\n",
    "        label = alphabet.decode(target)[0]\n",
    "        pred_label = alphabet.decode(preds)[0]\n",
    "        cer = character_error_rate(pred_label, label)\n",
    "        im_by_cer[cer].append((label, pred_label))\n",
    "        cnt[cer] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0.0: 350, 0.2: 43})\n"
     ]
    }
   ],
   "source": [
    "print(cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRUE        PRED        ERROR\n",
      "--------------------------------\n",
      "gny6b       gmy6b    {n}--->{m}\n",
      "xemyg       xenyg    {m}--->{n}\n",
      "nbp3e       nbp8e    {3}--->{8}\n",
      "gfp54       gfg54    {p}--->{g}\n",
      "ndecc       pdecc    {n}--->{p}\n",
      "3c7de       3c7be    {d}--->{b}\n",
      "f5cm2       f5cn2    {m}--->{n}\n",
      "7b4bm       7b4bn    {m}--->{n}\n",
      "5pm6b       5pm6p    {b}--->{p}\n",
      "wce5n       wxe5n    {c}--->{x}\n",
      "mbp2y       mbp2x    {y}--->{x}\n",
      "6pwcn       6pwcm    {n}--->{m}\n",
      "6c3n6       6c3m6    {n}--->{m}\n",
      "fc6xb       fc6xp    {b}--->{p}\n",
      "b43nw       b43mw    {n}--->{m}\n",
      "p8wwf       p8wwd    {f}--->{d}\n",
      "mmc5n       mmx5n    {c}--->{x}\n",
      "cwmny       ewmny    {c}--->{e}\n",
      "pwebm       pwebn    {m}--->{n}\n",
      "w6ny4       w8ny4    {6}--->{8}\n",
      "ffd6p       ffd5p    {6}--->{5}\n",
      "6e2dg       6e28g    {d}--->{8}\n",
      "gy8xb       gy8xp    {b}--->{p}\n",
      "5mfff       5nfff    {m}--->{n}\n",
      "5325m       5325n    {m}--->{n}\n",
      "3bfnd       3bfmd    {n}--->{m}\n",
      "wnpec       wmpec    {n}--->{m}\n",
      "2g783       2p783    {g}--->{p}\n",
      "y5w28       x5w28    {y}--->{x}\n",
      "77387       77367    {8}--->{6}\n",
      "p7fyp       p7fxp    {y}--->{x}\n",
      "5x5nx       5x5mx    {n}--->{m}\n",
      "7pn5g       7pn6g    {5}--->{6}\n",
      "m4g8g       n4g8g    {m}--->{n}\n",
      "42xpy       42cpy    {x}--->{c}\n",
      "dd5w5       dd5y5    {w}--->{y}\n",
      "ep85x       cp85x    {e}--->{c}\n",
      "xxbm5       xxbn5    {m}--->{n}\n",
      "wxcn8       wecn8    {x}--->{e}\n",
      "33f7m       33f7n    {m}--->{n}\n",
      "yfdn7       yfdm7    {n}--->{m}\n",
      "ennmm       cnnmm    {e}--->{c}\n",
      "42nxy       42mxy    {n}--->{m}\n"
     ]
    }
   ],
   "source": [
    "from multiset import Multiset\n",
    "\n",
    "max_cer = max(cnt.keys())\n",
    "print('TRUE        PRED        ERROR')\n",
    "print('--------------------------------')\n",
    "for true_lbl, pred_lbl in im_by_cer[max_cer]:\n",
    "    pred_err_smb = Multiset(pred_lbl) - Multiset(true_lbl)\n",
    "    true_err_smb = Multiset(true_lbl) - Multiset(pred_lbl)\n",
    "    print(f'{true_lbl}       {pred_lbl}    {true_err_smb}--->{pred_err_smb}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### На одной картинке максимум один неверный символ, т.е. качество  распознования достаточно хорошее\n",
    "##### Видно, что большинство ошибок предсказуемы - замена 'n' на 'm', '2' на '3', '5' на '3', '6' на '8' и т.п."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
